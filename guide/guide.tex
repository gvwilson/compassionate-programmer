\documentclass{report}
  \usepackage{alltt}
  \usepackage{graphicx}
\begin{document}

\newcommand{\FIXME}[1]{}
\newcommand{\comment}[1]{\footnote{#1}}

\newcommand{\appref}[1]{Appendix~\ref{#1}}

\newcommand{\chaplbl}[2]{\chapter{#1}\label{#2}}
\newcommand{\chapref}[1]{Chapter~\ref{#1}}

\newcommand{\seclbl}[2]{\section{#1}\label{#2}}
\newcommand{\subseclbl}[2]{\subsection{#1}\label{#2}}

\newcommand{\subsubseclbl}[2]{\subsubsection{#1}\label{#2}}
\newcommand{\secref}[1]{Section~\ref{#1}}

\newcommand{\caplbl}[2]{\caption{#1}\label{#2}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\tblref}[1]{Table~\ref{#1}}

\newcommand{\code}[1]{{\tt #1}}
\newcommand{\defterm}[1]{\emph{#1}}
\newcommand{\url}[1]{#1}

\begin{titlepage}
  \begin{center}
    \begin{huge}A Student's Guide to Small Software Projects\end{huge}
    \\
    \begin{Large}Greg Wilson\end{Large}
  \end{center}
\end{titlepage}

\newpage

\pagenumbering{roman}
\tableofcontents

\newpage

\pagenumbering{arabic}

% http://use.perl.org/~Ovid/journal/38616
% http://haacked.com/archive/2008/01/22/research-supports-the-effectiveness-of-tdd.aspx

%======================================================================
\chaplbl{Introduction}{s:intro}
%======================================================================

\begin{center}\begin{em}
Data is ones and zeroes. \\
Software is ones and zeroes and hard work. \\
Welcome to the third bit.
\end{em}\end{center}

I have been supervising undergraduate programming projects since 1987.
Some have been outright failures, but most have produced something of
value.  This book is what I think I've learned about what you, a
student doing a course built around a sizeable team-based software
project, can do to improve your odds of success.

Most of the material is based on my personal experiences, and
originally appeared in my blog \cite{b:third-bit-blog}.  The first
chapter is the most important---if you get those things wrong, none of
the other ideas I discuss will save you.  The chapters after that
cover student programming projects in general, how they are assessed,
how to work in teams, my take on development processes, software
tools, software design, and wrapping up projects.  If I missed
something important or made a mistake, please send mail to
\code{gvwilson@cs.toronto.edu} and let me know.

%======================================================================
\chaplbl{The Really Important Stuff}{s:important}
%======================================================================

In my experience, the things that go wrong most often in software
development projects---undergraduate or professional---have nothing to
do with software.  Instead, the worst mistakes people make are all
related to the human side of things.  Since some of you will only read
the first few pages of any document, I have put the three most
important topics here in a chapter of their own.

%----------------------------------------------------------------------
\seclbl{Meetings}{s:important-meetings}
%----------------------------------------------------------------------

I have a theory.  It's not about why there are no toilets on the
\emph{Enterprise}\footnote{Hint: transporters.}.  It's about why bad
software exists.

\begin{quotation}

  Fact \#1: the two biggest reasons software projects blow up are poor
  requirements management and integration failure: either the wrong
  thing is built, or the pieces don't work together when they're
  assembled.

  Fact \#2: the usual way to sort out requirements and negotiate
  interfaces is face-to-face discussion.  That means having meetings.

  Fact \#3: most people are really bad at meetings: they don't have an
  agenda going in, they don't take minutes, they waffle on or wander
  off into irrelevancies, they repeat what others have said or recite
  banalities simply so that they'll have said something, they hold
  side conversations (which pretty much guarantees that the meeting
  will be a waste of time), and so on.

  Conclusion: people create bad software because they're bad at
  meetings.

  Corollary: improve people's meeting skills, and you'll improve the
  software they produce.

\end{quotation}

So, here's how to run a meeting.
  
\emph{Start with an agenda.} If nobody cares enough about the meeting
to write a point-form list of what's supposed to be discussed, the
meeting itself probably doesn't need to happen.  Agendas also help you
keep the meeting moving (as in, ``That's very interesting, Yousuf, but
we have five other topics to get through in the next fifteen minutes,
so could you please make your point?'').

\emph{Only one person talks at a time.}  That means no side
conversations, no catching up with blogs, and no cell phones or
Blackberries.  This rule is important because:

\begin{enumerate}

  \item It's more efficient.  Nobody can actually pay attention to two
  things at once: if distractions are tolerated, people will miss
  things, or they'll have to be repeated, or both.

  \item Not paying attention is insulting---chatting with a friend on
  IM while someone explains what they did last week is a really
  effective way to say, ``I don't think your work is important.''

\end{enumerate}

\emph{Put someone in charge of the meeting.} ``In charge'' means
keeping the meeting moving, glaring at people who are muttering to one
another or checking email, and telling people who are talking too much
to get to the point.  It does \emph{not} mean doing all the talking;
in fact, whoever is in charge will usually talk less than anyone else,
just as a referee usually kicks the ball less often than the players.

\emph{No one is allowed to interrupt} (except the person in charge).
Raise a finger (no, not that one), or make one of the other gestures
people make at high-priced auctions instead if you want to speak next.
If the speaker doesn't notice you, the person in charge ought to.  Oh,
and while other people are talking, take notes of questions you want
to ask or points you want to make.  You'll be surprised how smart it
makes you look when it \emph{is} your turn to speak.

\emph{Have one person take minutes,} and circulate them (by email, or
in a blog or a wiki) by the end of the day of the meeting.  These
minutes aren't supposed to be a word-for-word record of who said what.
Instead, they should summarize the main points people made, the
questions that no one could answer, and the things people promised to
do, so that:

\begin{enumerate}

  \item \emph{People who weren't at the meeting can keep track of
  what's going on.}  You and your fellow students all have to juggle
  assignments from several other courses while doing this project,
  which means that sometimes you won't be able to make it to team
  meetings.  A wiki page, email message, or blog entry is a much more
  efficient way to catch up after a missed meeting or two than asking
  a team mate, ``Hey, what did I miss?''

  \item \emph{Everyone can check what was actually said or promised.}
  More than once, I've looked over the minutes of a meeting I was in
  and thought, ``Did I say that?'' or, ``Wait a minute, I didn't
  promise to have it ready then!''  Accidentally or not, people will
  often remember things differently; writing it down gives team
  members a chance to correct mistaken or malicious interpretations,
  which can save a lot of anguish later on.

  \item \emph{People can be held accountable at subsequent meetings.}
  There's no point making lists of questions and action items if you
  don't follow up on them later.  If you're using a ticketing system
  (\secref{s:tooling-ticketing}), the best thing to do is to create a
  ticket for each new question or task right after the meeting, and
  update those that are being carried forward.  That way, your agenda
  for the next meeting can start by rattling through a list of
  tickets.

\end{enumerate}

That's it.  Run all your meetings like this for a month, with the goal
of making each one a minute shorter than the one before, and I promise
that you'll build better software.

Oh, wait, there's one more rule: don't meet just to exchange
information.  Once you're using version control and tickets
(\secref{s:tooling}) you'll be able to keep track of your teammates'
actual progress via the web.  Meetings should be held to make
decisions about design (\secref{s:design}), work allocation
(\secref{s:teams-roles}), and what to cut when time gets tight
(\secref{s:process-cutting-corners}).  Remember, you can read faster
than anyone can speak: if someone has facts for the rest of the team
to absorb, the most polite way to communicate them is to type them in.

%----------------------------------------------------------------------
\seclbl{Crunch Mode}{s:important-crunch}
%----------------------------------------------------------------------

I used to brag about the hours I was working.  Not in so many words,
of course---I had \emph{some} social skills.  Instead, I'd show up for
class around noon, unshaven and yawning, and casually mention how I'd
been up 'til 6:00 a.m.\ hacking away at some monster bug or other.

Looking back, I can't remember who I was trying to impress.  Instead,
what I remember is how much of the code I wrote in those all-nighters
I threw away once I'd had some sleep, and how much damage the bugs I
created in those bleary-eyed stupors did to my grades.

My mistake was to confuse ``working'' with ``being productive''.  You
can't produce software (or anything else) without doing some work, but
you can easily do lots of work without producing anything of value.
Scientific study of the issue goes back to at least the 1890s (see
\cite{b:robinson-crunch-mode} for a short, readable summary).  The
most important results for students are:

\begin{enumerate}

\item Working more than eight hours a day for an extended period of
time lowers your total productivity, not just your hourly
productivity---i.e., you get less done in total (not just per hour)
when you're in crunch mode than you do when you work regular hours.

\item Working over 21 hours in a stretch increases the odds of you
making a catastrophic error just as much as being legally drunk.

\end{enumerate}

These facts have been reproduced and verified through hundreds of
experiments over the course of more than a century.  The data behind
them is as solid as the data linking smoking to lung cancer.  However,
while most smokers will admit that their habit is killing them, people
in the software industry still talk and act as if they were somehow
exempt from these findings.  To quote Robinson's article:

\begin{quotation}

  When Henry Ford famously adopted a 40-hour workweek in 1926, he was
  bitterly criticized by members of the National Association of
  Manufacturers. But his experiments, which he'd been conducting for
  at least 12 years, showed him clearly that cutting the workday from
  ten hours to eight hours---and the workweek from six days to five
  days---increased total worker output and reduced production
  cost{\ldots} the core of his argument was that reduced shift length
  meant more output.

  {\ldots}many studies, conducted by businesses, universities,
  industry associations and the military, {\ldots}support the basic
  notion that, for most people, eight hours a day, five days per week,
  is the best sustainable long-term balance point between output and
  exhaustion. Throughout the 30s, 40s, and 50s, these studies were
  apparently conducted by the hundreds; and by the 1960s, the benefits
  of the 40-hour week were accepted almost beyond question in
  corporate America. In 1962, the Chamber of Commerce even published a
  pamphlet extolling the productivity gains of reduced hours.

  But, somehow, Silicon Valley didn't get the memo{\ldots}

\end{quotation}

I was part of a data visualization startup in the mid-1990s.  Three
months before our first release, the head of development ``asked'' us
to start coming in on Saturdays.  We were already pulling one late
night a week at that point\footnote{With no mention of overtime
pay---our bosses seemed to think that ten dollars' worth of pizza was
adequate compensation for four hours of work.}, and most of us were
also working at least a couple of hours at home in the evenings.  It's
hardly surprising that we missed our ``can't miss'' deadline by ten
weeks, and had to follow up our 1.0 release with a 1.1, and then a
1.2, in order to patch the crash-and-lose-data bugs we'd created.  We
were all zombies, and zombies can't code.

Those kinds of hours are sadly still normal in many parts of the
software industry \cite{b:ea-spouse}, and also in university programs.
Everyone knows that designing and building software is a creative act
that requires a clear head, but many of those same people then act as
if it was like digging a ditch.

The big difference is that it's hard to lose ground when digging
(though not impossible).  In software, on the other hand, it's very
easy to go backward.  It only takes me a couple of minutes to
create a bug that will take hours to track down later---or days, if
someone else is unlucky enough to have to track it down.  This is
summarized in Robinson's first rule:

\begin{quotation}

  Productivity varies over the course of the workday, with the
  greatest productivity occurring in the first four to six
  hours. After enough hours, productivity approaches zero; eventually
  it becomes negative.

\end{quotation}

It's hard to quantify the productivity of programmers, testers, and
UI designers, but five eight-hour days per week has been proven to
maximize long-term total output in every industry that has ever been
studied.  There's no reason to believe that software development is
any different, or that student programming is different from full-time
programming in industry.

Ah, you say, that's ``long-term total output''.  What about short
bursts now and then, like pulling an all-nighter to meet a deadline?
Well, that's been studied too, and the results aren't pleasant.  Your
ability to think drops by 25\% for each 24 hours you're awake.  Put it
another way, the average person's IQ is only 75 after one all-nighter,
which puts them in the bottom 5\% of the population.  Two all nighters
in a row, and their effective IQ is 50, the level at which people are
usually judged incapable of independent living.

The catch in all of this is that \emph{people usually don't notice
their abilities declining}.  Just like drunks who think they're still
able to drive, people who are deprived of sleep don't realize that
they're not finishing their sentences (or thoughts).  They certainly
don't realize that they're passing parameters into function calls the
wrong way around, or that what they're typing in will all have to be
deleted and re-done tomorrow, when it will take longer than it would
have if they'd just gone home and gotten a good night's sleep.

The moral of this story?  Think very hard about what's more important
to you: the amount of good work you produce, or how much of a martyr
you appear to be.  Then think about which of those other people are
actually going to care about, and pace yourself accordingly.

%----------------------------------------------------------------------
\seclbl{Time Management}{s:important-time}
%----------------------------------------------------------------------

``But---but---I have so many assignments to do!'', you say.  ``And
they're all due at once!  I \emph{have} to work extra hours to get
them all done!''

No.  You can work \emph{smarter} instead.  I'm less intelligent than
many of the people I've worked with over the years.  I still manage to
get a lot done because I learned early on that organization and focus
are more important than raw IQ.

In order to be productive, you have to do two things: prioritize, and
focus.  The first is important because people are naturally very good
at spending hours on things that don't need to be done, and then
finding themselves with too little time for the things that actually
count.  It can actually be expressed as an algorithm:

\begin{enumerate}

  \item Make a list of the things you have to do.  I still use a
  hardcover lab notebook for this, since I can doodle in it when I'm
  on the subway, but a lot of people keep a personal wiki, or send
  themselves email messages that then go into a folder titled ``To
  Do''.  However you do it, the important thing is to \emph{write it
  all down}.  Your mind can only keep seven or so things in your
  short-term memory at once \cite{b:hock-forty-studies}; if you try to
  manage a to-do list longer than that in your head, you will forget
  things.

  \item Weed out everything that you don't need to do right away.
  Notice that I said ``need'', not ``want'': if you want to mess
  around with a new blogging tool, that's fine, but that's play time,
  not work time, and we're talking about getting work done.
  \FIXME{Large jobs and deadlines.}

  \item Prioritize what's left by sorting the list so that the most
  important tasks are at the top.  (I don't worry about getting the
  stuff below the first three or four lines into exact order, since
  I'm going to re-check my list before I get to them anyway.)

  \item Make sure you have everything you need to see the first task
  through: files from version control (\secref{s:tooling-versioning}),
  the assignment specification, whatever libraries and documentation
  you need, a fresh cup of coffee, a comfortable chair, etc.  Don't
  give yourself an excuse to interrupt your own work: the world will
  provide enough of those.

  \item Shut down your mail client, and turn off instant messaging and
  your cell phone.  Don't panic, it's only for an hour---most people
  can't stay focused longer than that, and anyway, you'll need to
  stretch your muscles and get rid of that coffee you drank.

  \item Set an alarm to go off in sixty minutes, and \emph{focus}.
  Don't switch tasks in that hour unless you absolutely have to.
  Instead, if you remember an email message that needs to be sent, or
  discover a couple of tests that really should be written, add a note
  to your to-do list.  (This is another reason I keep mine in a lab
  notebook: the few seconds it takes to pick up a pen and jot
  something down gives my hands a rest from the keyboard.)

  \item When your hour is up, take a break: check mail (but don't
  reply to anything that isn't urgent), go to the washroom, stretch a
  little, and then re-order your to-do list and start the next round.

\end{enumerate}

If any task on your list is more than an hour long, break it down into
into smaller pieces and prioritize those separately.  Keep in mind
that the future is approaching at a fixed rate of one day every 24
hours: if something's going to take sixty hours to do, you'd better
allow at least ten working days for it\footnote{Six rather than eight
because there are \emph{always} interruptions---if you can actually
spend 75\% of your time on the things you're supposed to be doing,
you're a lot better at staying focused than most people.}, which means
you'd better tackle the first piece two working weeks before the
deadline.  And since breaking large tasks down into small ones takes
time, don't be surprised if ``plan XYZ'' appears as a task in your
list.

The point of all this organization and preparation is to get yourself
into the most productive mental state possible.  Psychologists call it
\defterm{flow} \cite{b:csikszentmihalyi-flow}; athletes call it
``being in the zone'', while musicians talk about losing themselves in
what they're playing.  Whatever name you use, you will produce much
more per unit of time in this state than normal.

That's the good news.  The bad news is that it takes roughly ten
minutes to get back into a state of flow after an interruption, no
matter how short the interruption was.  This means that if you are
interrupted half a dozen times per hour, you are \emph{never} at your
productive peak.  It's very much like processes being paged in and out
by an operating system: if it happens too often, the CPU spends all
its time moving things around, and none doing useful work\footnote{ If
timeslicing is bad, why are schools set up to require you to do it
\emph{all the time}?  Doing nothing but the project course eight hours
a day for three weeks would be more efficient.  However, it would be
harder on instructors, and would be difficult to integrate with
courses in subjects like math and languages that take time to soak
in.}.

As a concrete example, a student of mine kept a stopwatch beside his
computer for a couple of weeks during term.  Every time he read mail,
put his instant messaging client in the foreground, or went to
Manchester United's web site, he hit the button to stop it.  At the
end of two weeks, he discovered that he only spent 28\% of his
``working'' time working.  Put it another way, he could have finished
his assignments in a third of the time they actually took.

If you want to get as much work done as possible, so that you will
have enough time for other things, it is therefore crucial that you
separate the two.  IM and your cell phone are great for socializing;
it's easy to tell yourself that you should leave them on so that your
teammates can reach you, but it just ain't true.  The best way to help
your teammates is to get your part of the project done; the best way
to show your significant other that you really love them is to finish
your assignments as quickly as you can so that you can go out and see
the latest Pixar movie without having to cut out and go back to the
lab.

Making lists and setting one-hour alarms will probably seem a little
earnest at first.  Trust me, though: your friends will stop mocking
you once they see that you're able to finish your assignments and
still have time to play some badminton and catch a movie.  They may
even start to imitate you.

%======================================================================
\chaplbl{Basic Mechanics}{s:basics}
%======================================================================

Now that the really important stuff is out of the way (you \emph{have}
read the previous chapter, haven't you?), let's take a closer look at
undergraduate team programming project courses.  These are bracketed
by two close cousins.  On one side are pure research projects, in
which the goal is to solve a problem.  These are usually done
individually, rather than in teams, and any software that's built is
just a means to an end.

On the other side are industrial internships or co-op terms, in which
you work full- or part-time for a company, drawing a salary and
suffering through quarterly PowerPoint presentations on corporate
strategy.  Lectures and exams usually aren't a part of these, though
if you're lucky (or if the company you're working for knows what it's
doing) you'll be paired with a mentor who will teach you some of the
things in these notes.

In between are courses with names like ``Introduction to Software
Engineering'', ``Senior Thesis Project'', or ``Computer Science
Capstone''.  For the purposes of this guide, these have three
characteristics.  First, \emph{learning how to work in a team is a
goal of the course}.  This distinguishes these courses from (for
example) upper-level courses in operating systems or computer
graphics, in which you're working in a team, but not being taught
explicitly how to do so.

Second, \emph{your grade depends primarily on the software your
build}.  You may also be required to write reports and sit an exam,
but these are based on the practical work---if you don't actually
build some software, you can't pass the course.

Finally, \emph{you are supposed to (pretend to) work as if you were in
industry, trying to meet the needs of a real customer.}  You might
start with a blank sheet of paper, or have to fix and extend an
existing application; either way, you and your team are responsible
for some or all of requirements analysis, design, implementation,
testing, documentation, packaging, deployment, handoff, and review.

Courses like this exist for several reasons:

\begin{itemize}

  \item \emph{To teach you things that can only be learned by doing.}
  If you pursue a career in industry, or if you go stay in academia
  and do anything other than pure theory, you will need to know how to
  build things.  This is a craft, not a science: you can't learn how
  by listening to lectures any more than you can learn to ride a bike
  by watching the Tour de France on TV.

  \item \emph{To tie everything you've learned together}, i.e., to
  demonstrate that the trees and pointers and joins and semaphores
  you've been wrestling with for the last two or three years are
  actually good for something.

  \item \emph{Because they're fun.}  

\end{itemize}

There are as many ways to run a project course as there are
instructors teaching them \cite{b:petre-projects}.  The most important
variable is whether your team has a real customer or not.  Finding and
interviewing people who actually want software built, and then meeting
their needs, is tremendously rewarding.  However, it's also a lot of
work, and puts an extra burden on the instructor as well.  For this
reason, most team projects tend to be made up by instructors.

A third option is to use an open source project as a starting point.
Whether it's an audio editor, a tool for displaying family trees, or
control software for the latest generation of electronic toys, the
odds are pretty good that there are bugs to fix and features to add.
Working on a project like this is easier than finding a local company
that wants its web site rejigged.  It's also an opportunity for you to
meet other developers who can mentor you, and create something you can
show off in a job interview\footnote{You might also want to check out
Google's Summer of Code program, which pays students a few thousand
dollars for working on a recognized open source project during their
summer break.}.

%----------------------------------------------------------------------
\seclbl{Grades}{s:basics-grades}
%----------------------------------------------------------------------

The first step in any project (not just classroom projects) is to
figure out where the goalposts are, so you know which way to kick the
ball.  If you're an academic, this means finding something that is
interesting and challenging enough to be publishable, but not
intractable.  In a startup, it means figuring out what you can build
that people will pay for.  Working for someone else?  Check your job
description (including criteria for performance evaluation and
bonuses), and work accordingly.

Life's easier if you're a student: all you have to do is check
the marking scheme.  In a project course, this typically has four
components:

\begin{enumerate}

  \item \emph{The software you produce.}  Does it build and run?  Does
  it meet the customer's requirements (or the instructor's
  specifications, if you don't have a real customer)?  Is the source
  code readable?  Is the program efficient?  (Using an exponential
  algorithm instead of one that runs in linear time certainly
  \emph{ought} to cost you marks{\ldots})

  \item \emph{The process you followed.}  Some instructors insist you
  use a traditional analyze-design-code-test methodology like the
  Rational Unified Process (RUP).  Others structure the course around
  short sprints (typically a couple of weeks long) during which you
  refactor the application, extend it, test your changes, and deploy
  the new version.  Since instructors can't watch over your shoulder
  while you're working, they can't actually grade you on whether or
  not you follow a prescribed process.  The best they can do is grade
  you on the artifacts that process is supposed to produce (discussed
  below).  Since these can always be created after the fact, it's very
  tempting to just put your head down and code.  Resist---as I'll
  discuss in \chapref{s:process}, any process is better than chaos,
  and sticking to what the instructor asked for will at least save
  arguments within the team.

  \item \emph{A final report} of the kind discussed in
  \secref{s:wrapup-report}.  This may be a handoff report (i.e.,
  documentation to help whoever inherits the software from you get up
  to speed), a summary of your experiences, or some combination of the
  two.

  \item \emph{A final exam.}  This may focus on the theoretical side
  of the course (``Describe the four main roles of a Quality Assurance
  department{\ldots}''), but smart instructors will include some
  questions to test your understanding of the project, in order to
  determine who actually did the work, and who was just along for the
  ride.

\end{enumerate}

Just like real development projects, course projects can and should
produce a lot more than just code.  To give you an idea of where the
effort actually goes in the real world, \tblref{t:freebsd-effort}
(taken from \cite{b:spinellis-effort}) shows how much content of
different kinds went into the FreeBSD project in 2006.  This table
doesn't divide ``source code'' into ``application code'' and
``tests'', but it's still an eye-opener.

\begin{table}
  \begin{tabular}{llll}

  Asset
  &
  Source
  &
  Size (KB)
  &
  Percentage
  \\

  Issues database
  &
  GNATS
  &
  711783
  &
  30.5\%
  \\

  Source code
  &
  C/C++
  &
  431519
  &
  18.5\%
  \\

  Documentation
  &
  troff, DocBook
  &
  114450
  &
  5.0\%
  \\

  Version history
  &
  CVS
  &
  1076762
  &
  46.0\%
  \\

  \end{tabular}

  \caplbl{Effort in FreeBSD (from \cite{b:spinellis-effort})}{t:freebsd-effort}

\end{table}

Here are some of the things that you might be required to produce
during your project:

\begin{itemize}

  \item \emph{Requirements analysis}: what the problem is, who the
  stakeholders are (i.e., who wants the problem solved), and what
  their needs are.

  \item \emph{Design}: what the user interface should look like, how
  data will flow through the system, what its major modules will be,
  and how they'll interact.

  \item \emph{Application Code}: the software that will be delivered
  to the end user.  This is inextricably entangled with:

  \item \emph{Test Code}: as I'll discuss in \secref{s:process-tdd},
  coding and testing should \emph{not} be separate activities---doing
  them concurrently greatly improves your project's chances of
  success.

  \item \emph{Documentation}: human-readable explanations of the
  software's structure and use.  The first is intended for whoever
  inherits the software from you; the second, for its users.  It is
  almost always a mistake to try to combine the two, or to write them
  as if they were going to be read by the same people.

  \item \emph{Packaging}: a program is a piece of software that runs
  for you on your machine.  A product is a piece of software that will
  run for anyone on \emph{their} machine.  Products take about three
  times longer to build than programs
  \cite{b:brooks-mythical-man-month}; the packaging needed to let
  someone else download, install, configure, and run the program has
  traditionally not been covered in software engineering courses, but
  good instructors will insist that you create it.

  \item \emph{Deployment}: these days, the project's aim might not be
  to create something that can be downloaded and installed.  Instead,
  its aim might be to create a web site or web service, or make
  something else directly available to users.  Like packaging,
  deployment can be a major development issue in its own right, and,
  like packaging, the effort required to do it is almost always
  underestimated.

  \item \emph{Handoff}: if you don't put effort into passing the
  project on to whoever comes after you, your hard work will almost
  certainly count for nought.  While it isn't usual for undergraduate
  projects to be handed on from one term to another, many courses
  require teams to swap code mid-term; if this happens, instructors
  may grade you on how complete and up-to-date your wiki pages, bug
  database, and build scripts are at the time of handoff
  (\secref{s:tooling}).

  \item \emph{Review}: the only way to get better at something is to
  reflect on how you've done, and what you could have done better.
  Every project should therefore end with a post mortem
  (\secref{s:wrapup-postmortem}), in which team members talk about
  what went right and what went wrong.  As mentioned earlier, this may
  then be the subject of the final report.

\end{itemize}

So much for generalities; the list below shows an actual grading
scheme that I've used in project courses (with minor variations) for
the last five years.

\begin{itemize}

  \item \emph{Warmup exercise} (10\%).  The warmup exercise is two
  weeks long; its purpose is to give students a chance to familiarize
  themselves with the problem domain, tools, and software they'll be
  using for the rest of the term.

  \item \emph{Analysis and estimation} (10\%).  Two weeks spent
  figuring out what your customers actually want, what features will
  satisfy their needs, etc.  This is discussed in details in
  \secref{s:process-plansched}.

  \item \emph{Code} (10\%).  Yes, that's right: the code is only worth
  10\% of the final grade, even though it's where students spend the
  bulk of their time.  There are two reasons for this: (1) if you
  don't know how to program, you shouldn't be in this course, and (2)
  if you don't create some code, you can't test, do a demo, or write
  your final report.

  \item \emph{Testing} (10\%).  Testing is just as important as
  coding, so it's given the same weight. Note, though, that only
  \emph{automated} tests count: if I can't check the project out of
  version control and re-run the tests (possibly after configuring a
  server or two), then as far as I'm concerned, \emph{the code hasn't
  been tested}.  And it's no good saying, ``But I can't write unit
  tests for my GUI'' because it's simply not true: if you design your
  program the right way, you can write tests for the back end, and
  tools like \url{Selenium} can test a lot more of your front end than
  you probably realize.

  \item \emph{Demos} (10\%).  I used to require students to prepare a
  20-minute PowerPoint lecture on a topic of their choosing, and
  deliver it to their coursemates or a junior class.  It was a
  valuable experience, but it ate up a lot of time.  These days, I
  usually have students do 10-minute demos instead.  I usually give
  students two shots at this: one after which their peers give them
  feedback, and a second that's actually graded.  This is valuable
  practice for job interviews (a growing number of employers want to
  see a programmer's portfolio before hiring her), and a good reality
  check on how much progress has actually been made.

  \item \emph{Teamwork} (10\%).  Everyone starts with 10 out of 10;
  marks come off if you always do your work at the last moment, check
  in code that breaks the build, or are disrespectful
  (\secref{s:teams-respect}).

  \item \emph{Final report} (20\%).  This describes the architecture
  of the code as it was actually built (rather than as it was
  designed).  It also summarizes the post mortem
  (\secref{s:wrapup-postmortem}), so that the next team to work on
  this project can avoid any pitfalls this team ran into.

  \item \emph{Final state of project} (20\%).  Most of my projects
  carry forward from term to term, and team to team, so I award one
  fifth of the overall mark based on the state each team leaves the
  project in: does everything build?  Have tickets been filed for all
  known issues?  Does the wiki explain how to install the code, and do
  those instructions actually work?

\end{itemize}

This grading scheme is labor-intensive: I probably spend 6-10 hours
reading and grading each project in a term.  I've thought several
times about using peer grading to reduce my load (and give students
some experience of what life is like on the other side of the red
pen), but I've never been able to convince myself that it would
actually work.

%----------------------------------------------------------------------
\seclbl{Elevator Pitch}{s:basics-pitch}
%----------------------------------------------------------------------

Once you know where the goalposts are, the next thing is to get
everyone to agree on what you're supposed to accomplish.  The best way
to do this is write a vision statement, also known as an
\defterm{elevator pitch}\footnote{The scenario is that you get on an
elevator with Bill Gates, and he says, ``So, what are you working
on?''  You have six floors to convince him to fund you---what do you
say?}.  Filling out the template in \tblref{t:pitch} (taken from
\cite{b:pollice-small-teams-rup}) will force you to think about what
problem you're trying to solve, who it affects, and why your solution
is a good one.  The bits on the left are boilerplate; the bits on the
right are to be filled in with something specific to your project.

\begin{table}
  \begin{tabular}{p{1.5in}p{4in}}

  The problem of
  &
  developing software in a predictable and reliable manner
  \\

  affects
  &
  the management of software projects.  Specifically, developers are
  not able to predict reliably how long it takes them to perform
  development tasks with acceptable quality, which makes it impossible
  to effectively plan a project.
  \\

  The impact is that
  &
  users and managers are never sure whether the produced software will
  meet its requirements, how reliable the software will be, or whether
  the software will be delivered on time.
  \\

  A successful solution would be
  &
  for developers to become more self-aware of what they do (i.e. the
  process they actually follow), how they spend their time, and the
  kinds of defects they find in their work.
  \\

  For
  &
  software development teams
  \\

  who
  &
  need to better understand how and when defects are introduced into
  their products,
  \\

  our product is a
  &
  tool for gathering and reporting performance metrics
  \\

  that
  &
  helps developers track and analyze personal software development
  metrics.
  \\

  Unlike
  &
  the alternative of failing to gather data, or trying to gather it
  manually,
  \\

  our approach
  &
  helps users gather data unobtrusively, and provides objective
  feedback that allows them to improve both individual and team
  performance.
  \\

  \end{tabular}
  \caplbl{Elevator Pitch Template}{t:pitch}
\end{table}

To start, have everyone on the team to fill it in independently, then
compare the results.  If your team is like most I've worked with,
you'll be surprised by how varied the answers are.  Once you've done
that, pick one and rewrite it so that everyone is happy with it, and
then turn it into a short paragraph like the one below:

\begin{quotation}

  Most programmers can't predict how long it will take them to do
  things because they don't know how long previous tasks have taken.
  Gathering data manually is annoying enough that programmers won't do
  it, so we're building a tool that will monitor what applications
  they use, and how long they use them.  This feedback will help them
  improve their working habits, and allow them to give their managers
  more accurate input for scheduling.

\end{quotation}

You now have the first paragraph for your project's home page, and the
abstract for your final report.

An alternative to writing a vision statement is to ``design the box'',
i.e., to make up the package that your software would ship in if it
was going to be sold to customers off the shelf\footnote{Joel Spolsky
attributes this idea to Jim Highsmith.}.  What catchphrase would you
put across the top to catch people's eyes?  What features would you
list on the back to make your software more appealing than its
competitors?  What would its system requirements be?  Its license?
Its price?  Once your team agrees on these things, you're ready to
start designing and coding.

%======================================================================
\chaplbl{Teams}{s:teams}
%======================================================================

Study after study has shown that students learn better in small teams
than they do on their own.  As long as their teams are run well,
students achieve higher grades, retain information longer, are less
likely to drop out of school, and graduate with better communication
skills and a better understanding of what will be expected of them in
their subsequent careers \cite{b:oakley-teams}.

That ``as long as'' is important.  A badly-run team is worse than no
team at all, since people will waste hours or days arguing with one
another, duplicating or undoing each other's work, and wishing that
they had gone into gardening instead.  These conflicts are more
wearying than any number of buffer overruns or accidentally erased
files, which is why most computer science courses stick to individual
assignments.

It doesn't take much to make a team work smoothly, though.  All you
have to do is follow some common-sense advice, and be willing to stand
up to people who aren't playing by the rules.  I'll talk more about
what people in a team actually \emph{do} in a development project in
\chapref{s:process}.

%----------------------------------------------------------------------
\seclbl{Picking Teams}{s:teams-picking}
%----------------------------------------------------------------------

I once heard an anthropologist ask a room, ``How big is a sports
team?''  When people said they are all different sizes, she explained
that in fact, they all have about half a dozen members.  Anything
larger than that splits into smaller groups: the forwards and backs in
rugby, the infield and outfield in baseball, and so on.

She went on to explain that hunting parties in non-agricultural
societies are usually that size as well, as are basic military units
around the world (a platoon is two squads of six guys each).  She
thought there was a biological reason for this: we can only keep seven
or so things in our short-term memory at once
\cite{b:hock-forty-studies}, so that's as big as a team can
practically be.

The same observation applies to software development.  Three or four
people can work tightly on a single piece of code, but when there are
more, they divvy up the work, define some interfaces, and go their
separate ways.  Collaborative tools like bug trackers
(\chapref{s:tooling}) allow groups to coordinate more effectively, but
the groups themselves stay the same size.

In practice, research shows that \emph{teams of three to five are most
effective}, at least for student projects\comment{Need a citation for
this}.  A team of two may not have enough breadth and background to
tackle a large piece of work.  More importantly, one or the other
person is likely to take a dominant role and win all the arguments
(whether she's right or not).  If you put six people in a team, on the
other hand, you may not be able to divide up the work in a way that
will keep everyone engaged and busy.  Teams that size also increase
the odds that at least one member will be either a
\defterm{hitchhiker}, or a \defterm{rudie}.

Research also shows that \emph{teams formed by instructors work better
than self-selected teams}.  Students typically complain about this,
sometimes vehemently: they want to work with their friends, they don't
want to be slowed down by teammates who are slower or less dedicated
than they are, they have a part-time job and can only get together
regularly with their housemates, and so on.

Good instructors will ignore all of these objections except the last
one. If students are allowed to form their own groups, they tend to
clump together by ability.  It's easy to see how this hurts teams of
weak students: they are less likely to be able to fill in the gaps in
one another's knowledge.  However, it also hurts teams of stronger
students.  As any teacher can tell you, the best way to learn
something is to explain it to someone else.  Bringing a weaker
teammate up to speed will usually do more for your grade than spending
those same hours hacking or reading.

In addition, teams of strong students are more likely to use a divide
and conquer strategy, effectively reducing the project to a set of
independent sub-projects, each of which is then tackled by only one
person.  This may feel more efficient, but in practice, most of the
benefits of working in a team are lost: there's less back-and-forth
discussion of design issues, and little improvement in communication
skills.  Those may not be important to you, but if there is a final
exam in your course with questions about the project work, your mark
on it will depend on how much you know about your teammates' work.

There's another strong argument against self-selected teams: the
pre-existing or ongoing relationships between their members make life
a lot easier for hitchhikers, and a lot harder for everyone else.
It's hard enough to tell someone they're not pulling their weight;
it's a lot harder when that person is also on your volleyball team.

The most powerful argument for instructors selecting teams, though,
is, ``That's how it works in the real world.''  If you join a company
or an academic research group, you won't get to pick your colleagues;
you'll be put on a project, and expected to work---and work
well---with whoever else is on it.  Your performance will depend as
much on your ability to get along with others as it will on your raw
technical ability, so you might as well start practicing those skills
now.

While instructors should try to include as diverse a spread of
abilities in each team as possible, they should avoid isolating
at-risk students.  Members of minority groups and women are more
likely to drop out of computer science, particularly in first and
second year.  I'll talk about this more in \secref{s:teams-respect},
but one of the main reasons is feeling isolated or out of place.
Research has shown shown that putting at-risk students together in the
first couple of years can mitigate this problem
\cite{b:margolis-fisher-unlocking-clubhouse}.  It is less necessary in
upper years, though, since by then students have a stronger commitment
to whatever program they're in.

The biggest headache when instructors select teams is scheduling.  My
university serves a large metropolitan area; it has three campuses,
and some students commute an hour and a half each way to get to
classes.  Instructors can usually take students' schedules into
account when forming teams.  If the class is small, the simplest way
is to get each student to fill in a weekly timesheet showing when
they're available, and then group people who have large blocks of
overlap.  If the class is larger, a web-based calendaring tool may be
easier\footnote{It would be easier still if iCal, Outlook, and Google
Calendar would all talk to one another{\ldots}}.  Instructors can even
try to use whatever software the university uses to figure out course
timetables, although that usually doesn't scale down to intra-class
scheduling.

Another factor to take into account is that some people are naturally
early birds, while others are night owls.  Putting the two on the same
team pretty much guarantees that someone will miss meetings, or sleep
through them, no matter when they're held.  Simply asking people, ``Do
you prefer to work in the morning, or the evening?'' can be
surprisingly effective.

However you form teams, \emph{each team must have at least one block
of two hours to work together each week}, outside of class.  Teams
should also try to find a second block that's half an hour long for a
weekly meeting.  Try to keep the two blocks separate, so that it's
clear to everyone when you're supposed to be talking about the
project, and when you're supposed to be doing design, building
software, testing, and so on.  If the two are scheduled back-to-back,
the meeting will drag on into working time or vice versa.

%----------------------------------------------------------------------
\seclbl{Who Does What?}{s:teams-roles}
%----------------------------------------------------------------------

All right, you've formed a team: now what?  How do you decide who does
what?  And just as importantly, how do you make sure that everyone
actually does what they're supposed to?

There are many ways to divide project work between team members.  In a
\emph{modular decomposition}, each person is responsible for all
aspects of one part of the program.  For example, one person might
design and build the GUI, while another writes the database interface,
and a third implements the business rules.  This is generally a bad
strategy for three reasons:

\begin{enumerate}

  \item Unless the team is very disciplined, it leads to \defterm{big
  bang integration}, in which all the components meet each other for
  the first time right at the end of the project.  Big bang almost
  always fails.

  \item Each team member only really understands one aspect of the
  project as a whole.  This can hurt a lot if there's a final exam
  (which is just a pointed way of saying ``team members will learn
  less'').

  \item If someone drops out or fails to complete their module, the
  project as a whole will fail.

\end{enumerate}

\emph{Functional decomposition}, in which each person is responsible
for one type of task, is usually more successful.  With this strategy,
one person does the testing, another handles the documentation, a
third does the bulk of the coding, and the fourth takes care of build
and deployment.  This guarantees that everyone understands most of the
project by the end of the term.  The obvious drawback is that each
person only gets to hone one set of skills.

Another, less obvious, drawback stems from the fact that some
activities are viewed as being more prestigious than others.  If the
team decomposes work functionally, the self-appointed ``alpha geeks''
will usually wind up with the plum jobs, like architecture and coding,
leaving less appealing work to people who aren't as pushy or
self-confident.  This tends to reinforce existing inequities
(\secref{s:teams-respect}); it also tends to lower the team's overall
grade, since there's often little relationship between how outspoken
people are and how well they work.

\emph{Uniform decomposition} is a scaled-down version of modular
decomposition that is much more effective.  Instead of owning an
entire module for the lifetime of the project, each developer does the
design, coding, testing, and documentation for one small feature after
another.  Working this way is central to agile development
(\secref{s:process-agile-sturdy}), and is a good way to cope with the
never-ending timeslicing of student life.

Finally, there is \emph{rotating decomposition}: everyone does one
task for a few weeks, then a different task for the new few, and so
on\footnote{The boss of the last product group I worked in rotated
developers into testing for a few weeks at the end of every release
cycle.  I learned more about the product I was building in those weeks
than I learned in the rest of the year; configuring the product to
work with databases I'd never even heard of before, and exercising
features I only vaguely knew existed, paid dividends many times
over.}.  This is initially less productive in absolute terms than
either of the preceding strategies, since the team has to pay for
ramp-up several times over.  In the long term, though, it outperforms
the alternatives: it is more robust (having a team member drop out is
less harmful), and if everyone on the team is familiar with every
aspect of the software, they can all contribute to design and
debugging sessions.

Any of these strategies is better than \emph{chaotic decomposition}.
If people have different ideas about who's supposed to do what, some
things won't be done at all, while others will be done several times
over.  (You can tell if your decomposition is chaotic by counting how
many times people says, ``I thought \emph{you} were doing that!''  or
``But I've already done that!''  The more often these phrases are
heard, the more trouble you're in.)  All other decompositions tend
toward chaos under pressure, so it's important to establish rules
early, and stick to them when the going is easy, so that the instinct
to do the right thing will be there when you need it.

Your instructor may mandate a particular work decomposition.  If she
does, your first team meeting should be devoted to deciding who will
do what.  Do \emph{not} allocate work on the basis of who's loudest or
most willing to interrupt: remember, there's only a weak correlation
between how confident someone is, and how competent they are
\cite{b:kruger-dunning-competence}.

No matter what decomposition you use, your team should write, sign,
and hand in a contract outlining what everyone has agreed to do to
make the project a success.  In my experience, this is a lot more
effective if students make it up themselves as their first assignment;
that way, they actually have to think about what they're promising
their teammates.  Here's an example:

\begin{quotation}

  We, the members of Team 12, agree the following:

  \begin{enumerate}

    \item Work on each assignment will be divided according to role.
    Two people will code, one will test, and one will be responsible
    for documentation.  One of the coders will run the weekly meeting;
    the other will take minutes, and post them to the project wiki and
    mailing list on the same day as the meeting.  These roles will
    rotate for each assignment.  No one will code two assignments in a
    row.

    \item The tester will be responsible for actually submitting the
    assignment.  Someone will only be listed as contributing to that
    assignment if at least two other members of the team think she
    completed, or made significant progress on, at least one work
    item.

    \item We will aim to get at least 80\% on each assignment.

    \item We will hold a half-hour status meeting every week on
    Thursdays at 4:00 pm.  Everyone will attend, and be on time.  If
    someone cannot attend, they will let the rest of the team know by
    email no later than noon on that day.

    \item Everyone will email a brief point-form summary of their
    progress during the week to the team mailing list no later than
    noon on Thursday.  Everyone will read everyone else's summary
    before the 4:00 meeting and make a list of their questions and
    concerns.

    \item All email about the project will go to the team mailing
    list, rather than person-to-person.  Everyone will check email at
    least twice a day during the week, and at least once a day on
    weekends.

    \item No one will check code into version control that fails to
    compile.  No one will check in code that fails to pass existing
    tests without first getting the permission of that round's tester.
    No one will change the database schema or add dependencies on
    third-party or open source libraries without first getting
    permission from the whole team.

  \end{enumerate}

\end{quotation}

It may sound a little silly, like those ``contracts'' that some
parents and children make up regarding chores and allowances, but
it's actually very effective.  First, people really do have
different expectations about what being in a team means.  Some
people, for example, may be happy with a bare pass; others may
want the team to shoot for an A+ on everything.  Knowing who wants
what won't make these tensions go away, but it certainly helps
focus the argument.

Drawing up a contract also prevents later disagreements about who
actually promised or agreed to what.  As with meetings
(\secref{s:important-meetings}), people often remember things
differently; having a signed record is everyone's second-best
defense\footnote{The best, of course, is personal integrity.}.

I still don't know if teams should have to give copies of their
contracts to their instructors or not.  On the one hand, it's a great
way to let your instructor know how you're planning to operate, and
what you're planning to achieve.  Given that she probably has a lot
more experience than you, it gives her a chance to tell you if you've
forgotten anything, or how well those really cool ideas your teammate
talked you into\footnote{Lisp!  Lisp!  All the \emph{really} cool
programmers use Lisp!} will actually work.  On the other hand, as soon
as something has to be handed in, some students will write what they
think the instructor wants to read, rather than what they actually
think.

Two last notes.  First, most software development teams in industry
and open source don't bother with contracts like these.  There may be
corporate guidelines on good citizenship\footnote{Usually drawn up by
committees packed with people who knew all five verses of the high
school cheer.}, or performance metrics written into your job
spec\footnote{``You can't manage what you don't measure'' is a truism
in the business world.  Unfortunately, so is, ``You only get what you
reward.''  If developers are rewarded for the number of lines of code
they write, they will write overly-verbose code; if they are rewarded
for the number of bugs they find, they won't bother to do any testing
up front, since that would actually lower their score.  I think
metrics are valuable, but it requires a lot of maturity (and the
ability to reflect on what they actually mean) to realize that
value.}, but in general, people expect that if you're doing this for a
living, you know what others can reasonably expect of you, and you
will live up to those expectations.  (This often turns out not to be
the case, which is one of the reasons so many real-world projects
fail.)

Second, if your instructor has you draw up a team contract at the
start of the project, then she can and should base part of your team's
grade on how well you stuck to it.  If she handed you a team contract,
she should definitely base part of the grade on compliance.  If there
was no contract at all, then I think it's unfair to turn around at the
end of the project and ask people to rate one another, since they
won't have known while they were working what they were going to be
rated on.

Asking people on a team to rate their peers is a common practice in
industry.  Instructors sometimes shy away from it because they're
afraid students will gives everyone in the team a high rating in order
to boost grades.  However, the evidence shows that this actually
occurs fairly infrequently \cite{b:kaufman-felder-accounting}.

What's more, as long as evaluation is based on observables, rather
than personality traits, peer assessment can actually be as accurate
as assessment by TAs and other outsiders.  ``Observables'' means that
instead of asking, ``Is the person outgoing,'' or ``Does the person
have a positive attitude,'' assessments should ask, ``Does the person
listen attentively during meetings,'' or, ``Does the person attempt to
solve problems before asking for help.''  \tblref{t:eval-form} shows a
sample evaluation form, taken from \cite{b:seat-mcanear-team} to get
you started.  To use it, rank yourself and each of your teammates,
then calculate and compare scores.

\begin{table}
  \begin{itemize}
    \item \textbf{Communication}
      \begin{itemize}
      \item Listens attentively to others without interrupting
      \item Clarifies with others have said to ensure understanding
      \item Articulates ideas clearly and concisely
      \item Gives good reasons for ideas
      \item Wins support from others
      \end{itemize}
    \item \textbf{Decision Making}
      \begin{itemize}
      \item Analyzes problems from different points of view
      \item Applies logic in solving problems
      \item Offers solutions based on facts rather than ``gut feel'' or intuition
      \item Solicits new ideas from others
      \item Generates new ideas
      \item Accepts change
      \end{itemize}
    \item \textbf{Collaboration}
      \begin{itemize}
      \item Acknowledges issues that the team needs to confront and resolve
      \item Encourages ideas and opinions even when they differ from his/her own
      \item Works toward solutions and compromises that are acceptable to all involved
      \item Shares credit for success with others
      \item Encourages participation among all participants
      \item Accepts criticism openly and non-defensively
      \item Cooperates with others
      \end{itemize}
    \item \textbf{Self-Management}
      \begin{itemize}
      \item Monitors progress to ensure that goals are met
      \item Puts top priority on getting results
      \item Defines task priorities for work sessions
      \item Encourages others to express their views even when they are contrary
      \item Stays focused on the task during meetings
      \item Uses meeting time efficiently
      \item Suggests ways to proceed during work sessions
      \end{itemize}
  \end{itemize}
  Scale: Never (1), Rarely (2), Sometimes (3), Frequently (4), Always (5)
  \caplbl{Team Evaluation Form}{t:eval-form}
\end{table}

This may all seem rather fuzzy for a course that's supposed to be
about building software.  But as the performance review guidelines in
\appref{s:evaluation} shows, how well you code is only a one part of
how useful you are to a software development company.

%----------------------------------------------------------------------
\seclbl{Dealing With Conflict}{s:teams-conflict}
%----------------------------------------------------------------------

Grades just came back for the second assignment.  Your team got 51\%,
which is far lower than you're used to.  The sick feeling in the pit
of your stomach has turned to anger: you did \emph{your} part, and so
did most of the rest of the team, but Marta didn't turn in her stuff
until the very last minute, which meant that no one else had time to
spot the two big mistakes she'd made.  As for Chul, well, he didn't
turn his stuff in at all---again.  If something doesn't change, this
course is going to pull your GPA down so far that you might lose your
scholarship.

Situations like this come up all the time in the real world, and in
all parts of life.  Broadly speaking, there are four ways you can deal
with them:

\begin{enumerate}

  \item Cross your fingers and hope that things will get better on
  their own, even though the last eight times you hoped they would,
  they didn't.

  \item Do extra to make up for others' shortcomings.  This sometimes
  seems to work in the short term, and saves you the mental anguish of
  confronting others, but the time for that ``extra'' has to come from
  somewhere; what usually ends up happening is that other courses, or
  your personal life, suffer.

  \item Lose your temper and start shouting.  Unfortunately, people
  often wind up displacing their anger into other parts of their life:
  I've seen developers yell at waitresses for bringing incorrect
  change when what they really needed to do was tell their boss, ``No,
  I \emph{won't} work through another holiday weekend to make up for
  your decision to short-staff the project.''

  \item Take constructive steps to fix the underlying problem.
 
\end{enumerate}

Most of us find number four hard because we don't like confrontation.
If you manage confrontation properly, though, it is a lot less
bruising, which means that you don't have to be as afraid of
initiating it.  Also, if people believe that you will actually take
steps when they bully, lie, procrastinate, or do a half-assed job,
they will almost always pull up their socks.

Here are the steps you should take when you feel that a teammate isn't
pulling his or her weight:

\begin{enumerate}

  \item \emph{Make sure you're not guilty of the same sin.} You won't
  get very far complaining about someone else interrupting in meetings
  if you do it just as frequently.

  \item \emph{Check expectations.} Are you sure the offender knows
  what standards he is supposed to be meeting?  This is where a team
  contract comes in useful.

  \item \emph{Document the offense.} Write down what the offender has
  actually done, and why it's not good enough.  Doing this will help
  you clarify matters in your own mind.  It's also absolutely
  necessary if you have to escalate.

  \item \emph{Check with other team members.} Are you alone in feeling
  that the offender is letting the team down?  If so, that doesn't
  necessarily mean you're wrong, but it'll be a lot easier to fix
  things if you have the support of the rest of the
  team\footnote{Finding out who else on the team is unhappy can be the
  hardest part of the whole process, since you can't even ask the
  question without letting on that you're upset, and word will almost
  certainly get back to whoever you're asking about, who might then
  turn around and accuse you of stirring up trouble.  After a couple
  of unhappy experiences of this kind, I've learned that it's best to
  raise the issue at a team meeting in front of everyone.}.

  \item \emph{Talk with the offender.} This should be a team effort:
  put it on the agenda at a team meeting, present your complaint, and
  make sure that the offender understands it.  In most cases, this is
  enough: human beings are herd animals, and if someone realizes that
  they're going to be called on their hitchhiking or bad manners, they
  will usually change their ways.

  \item \emph{Escalate as soon as there's a second offense.}
  Hitchhikers and others who really don't have good intentions are
  counting on you giving them one ``last chance'' after another until
  the term is finished and they can go suck the life force out of
  their next victim.  \emph{Don't fall into this trap.}  If someone
  stole your laptop, you'd report it right away.  If someone steals
  your time or your grades, you're being pretty generous giving them
  even one chance to mend their ways.

\end{enumerate}

In the context of a student project, ``escalation'' means ``taking the
issue to the instructor''.  (If you're reluctant to do this because
you don't want to be a snitch, go back and read what I just wrote
about people stealing your laptop.)  Of course, your instructor has
probably had dozens of students complain to her over the years about
partners and teammates not doing their share\footnote{It isn't
uncommon to have both halves of a pair tell the instructor that
they're doing all the work.  This is one of the reasons I insist that
students use version control to manage their projects: it lets me
check who's actually written what.}.  In order to get her to take you
seriously and help you fix your problem, you should send her an email,
signed by the whole team (or as many as you can get on side)
describing the problem and the steps you have already taken to resolve
it.  Make sure the offender gets a copy as well, and ask your
instructor to arrange a meeting to resolve the issue.

This is where documentation (step three in the list above) is crucial.
Hitchhikers are usually very good at appearing reasonable; they're
very likely to nod as you present your case, then say, ``Well, yes,
but{\ldots}'' and rhyme off a bunch of minor exceptions, or cases
where others on the team have also fallen short of expectations.  If
you can't back up your complaint, your instructor will likely be left
with the impression that the whole team is dysfunctional, and nothing
will improve.

One technique your instructor may ask you to use in a meeting of this
kind is \defterm{active listening}.  As soon as one person makes a
point, the person on the opposite side of the issue explains it back
to him, as in, ``So what I think Igor is saying is{\ldots}'' This
guarantees that the second person has actually paid attention to what
the first person said.  It can also defuse a lot of tension, since
explaining your position back to you clearly forces the other person
to see the world through your eyes, if only for a few moments.

%----------------------------------------------------------------------
\seclbl{People to Watch Out For}{s:teams-uhoh}
%----------------------------------------------------------------------

Tolstoy wrote that all happy families resemble one another, but each
unhappy family is unhappy in its own way.  Similarly, all good team
members share certain characteristics, but bad ones can be bad in many
different ways.  Here are a few:

\begin{itemize}

  \item \emph{Anna} knows more about every subject than everyone else
  on the team put together---at least, she thinks she does.  No matter
  what you say, she'll correct you; no matter what you know, she knows
  better.  Annas are pretty easy to spot: if you keep track in team
  meetings of how often people interrupt one another, her score is
  usually higher than everyone else's put together.

  \item \emph{Bao} is a contrarian: no matter what anyone says, he'll
  take the opposite side.  This is healthy in small doses, but when
  Bao does it, there's always another objection lurking behind the
  first half dozen.

  \item \emph{Caitlin} has so little confidence in her own ability
  (despite her good grades) that she won't make any decision, no
  matter how small, until she has checked with someone else.
  Everything has to be spelled out in detail for her so that there's
  no possibility of her getting anything wrong.

  \item \emph{Frank} believes that knowledge is power.  He enjoys
  knowing things that other people don't---or to be more accurate, he
  enjoys it when people know he knows things they don't.  Frank can
  actually make things work, but when asked how he did it, he'll grin
  and say, ``Oh, I'm sure you can figure it out.''

  \item \emph{Hediyeh} is quiet.  Very quiet.  She never speaks up in
  meetings, even when she knows that what other people are saying is
  wrong.  She might contribute to the mailing list, but she's very
  sensitive to criticism, and will always back down rather than
  defending her point of view.  Hediyeh isn't a troublemaker, but
  rather a lost opportunity.

  \item \emph{Kenny} is a hitchhiker.  He has discovered that most
  people would rather shoulder some extra work than snitch, and he
  takes advantage of it at every turn.  The frustrating thing is that
  he's so damn \emph{plausible} when someone finally does confront
  him.  ``There have been mistakes on all sides,'' he says, or,
  ``Well, I think you're nit-picking.''  The only way to deal with
  Kenny is to stand up to him: remember, if he's not doing his share,
  \emph{he's the bad guy}, not you.

  \item \emph{Melissa} would easily have made the varsity
  procrastination team if she'd bothered to show up to tryouts.  She
  means well---she really does feel bad about letting people
  down---but somehow something always comes up, and her tasks are
  never finished until the last possible moment.  Of course, that
  means that everyone who is depending on her can't do their work
  until \emph{after} the last possible moment{\ldots}

  \item \emph{Petra}'s favorite phrase is ``why don't we''.  Why don't
  we write a GUI to help people edit the program's configuration
  files?  Hey, why don't we invent our own little language for
  designing GUIs?  Her energy and enthusiasm are hard to argue with,
  but argue you must.  Otherwise, for every step you move forward, the
  project's goalposts will recede by two.  This is called
  \defterm{feature creep}, and has ruined many projects that might
  otherwise have delivered something small, but useful.

  \item \emph{Raj} is rude.  ``It's just the way I talk,'' he says,
  ``If you can't hack it, maybe you should find another team.''  His
  favorite phrase is, ``That's stupid,'' and he uses obscenity as
  casually as minor characters in Tarantino films.  His only redeeming
  grace is that he can't dissemble in front of the instructor as well
  as Kenny, so he's easier to get rid of.

  \item \emph{Sergei} is simply incompetent.  He doesn't understand
  the problem, he hasn't bothered to master the tools and libraries
  he's supposed to be using, the code he checks in doesn't compile,
  and his thirty-second bug fixes introduce more problems than they
  solve.  If he means well, try to re-partition the work so that he'll
  do less damage.  If he doesn't, he should be treated like any other
  hitchhiker.

\end{itemize}

%----------------------------------------------------------------------
\seclbl{Irreconcilable Differences}{s:teams-failure}
%----------------------------------------------------------------------

Sometimes, it isn't just one person on the team who's a problem.
Sometimes, the whole team is dysfunctional.  In the mid-1990s, for
example, I worked in a data visualization startup.  Individually, we
were all smart, decent people.  Put us together, though, and somehow
our personalities and IQs canceled out, leaving us all dumb and nasty.

According to \cite{b:oakley-teams}, instructors can allow for this by
announcing at the start of the course that teams will be dissolved and
re-formed halfway through the project, \emph{unless} every member on
the team submits a separate signed request to stay together.  There's
a bit of psychology here: if people are required to ask for their team
to be dissolved, they will often think, ``It's more trouble than it's
worth, I'll just put up with it.''  If dissolution is the default,
though, then students won't be inhibited by any stigma attached to
being the one who caused trouble.

Students also usually understand that dissolving their team and
forming a new one takes time that could be invested in earning a
higher grade.  In practice, therefore, teams will almost always choose
to stick together if they see that hitchhikers and rudies are actually
being dealt with.

%----------------------------------------------------------------------
\seclbl{Respect}{s:teams-respect}
%----------------------------------------------------------------------

And now for a topic most undergraduates would rather not think about.
There's an element of truth in the popular stereotype of programmers
having poor social skills.  It might be self-selection: if you don't
like people much, or find it hard to navigate the vicious unwritten
rules of high school dances, computers will be your friends.
Alternatively, it may be something that young programmers learn from
their grumpy, poorly-dressed mentors.  Whatever it is, it's bad, and
you should fight it.  In particular, \emph{if you and your teammates
don't respect one another, your project will fail}.  You won't be able
to run a meeting, or divide up work fairly; you especially won't be
able to cope with the pressure when things go wrong.

People can be disrespectful on many levels.  The most obvious is
simple rudeness, which in student teams usually takes the form of
interrupting people.  I've been in meetings in which no one could get
more than a sentence and a half out before someone would cut them
off. The signal people send when they do that is that they think their
teammates are less intelligent than they are.  In fact, the reverse is
usually true: if someone isn't smart enough to realize that letting
his teammates finish their thoughts is productive as well as polite,
he's probably just not smart, period.

Disrespect can take more serious forms.  For example,
\figref{f:women-science} shows that the number of women earning
bachelor's degrees in science and engineering in the US has been
climbing steadily since the 1960s.  \figref{f:women-cs}, on the other
hand, shows that the number of women earning bachelor's degrees in
Computer Science has been dropping, even as male numbers have risen.

\begin{figure}
  \includegraphics[scale=0.5]{sci-eng-degrees.png}
  \caplbl{Science and Engineering Degrees 1966-2004 (from \cite{b:women-science-stats}).}{f:women-science}
\end{figure}

\begin{figure}
  \includegraphics[scale=0.5]{cs-degrees.png}
  \caplbl{Computer Science Degrees 1985-2004 (from \cite{b:women-science-stats}).}{f:women-cs}
\end{figure}

Why is that?  Why are women choosing not to do computer science
degrees, even while they're entering other sciences (and professions
like law and medicine) in ever-increasing numbers?

Well, here's another fact: not only do fewer women go into computer
science than men, the dropout rate among female students is higher
than it is among males.  Studies like
\cite{b:margolis-fisher-unlocking-clubhouse} have shown that this has
nothing to do with intelligence, grades, or ability to do the work.
Instead, women are more likely to be made to feel that they don't
belong, or that computing ``isn't for them''.  Even a small amount of
unequal pressure can have a large result: if there's just a 10\%
chance per year of a female student dropping out because the guys
around her are listening to ``Slap My Bitch Around'' in the lab, or
because her male partners have decided to ``take care of'' the coding
in the graphics course project, and left the testing and documentation
for her, then \emph{one third} of women will be gone after four years.

``Hey, survival of the fittest, dude---if women can't handle the
pressure, they should study something else.''  I've heard that
argument many times, and my answer is always the same: if a 200-pound
Phys Ed student came up to you, whacked you on the head, and took your
wallet and iPod, you wouldn't shrug and say, ``Survival of the
fittest.''  The fact that what you're doing doesn't involve physical
assault doesn't make it any less unfair.

Here's a story to illustrate what I mean.  The first time I taught a
programming course at the \url{University of Toronto}, I had my
students write a couple of five-line biographies for themselves as a
way to get used to checking things into CVS.  In the first, they were
to describe who they were; in the second, they were to describe who
they hoped to be in ten years' time.  A quarter of the male students
made a point of mentioning their ``beautiful'' wife in the second bio;
a few even specified that she was an actress or a model.

When I pointed this out to the class, many of them laughed.  I don't
think they'd have laughed as hard if I'd said, ``A quarter of the
white students think they're going to have Chinese houseboys doing
their laundry ten years from now.''  And if they thought that most
programmers saw them that way, I bet that fewer of them would choose
to become programmers themselves.  Pervasive disrespect is like water
dripping on a stone: no single drop seems to matter much, but its
erosive effects are tremendously powerful.

It's important to realize that \emph{the forces that make computing
uncongenial for women also make it uncongenial for a lot of men}. If
you're a guy with a well-balanced life who thinks social skills
matter, you're going to be subject to many of the same differential
pressures as your female colleagues.  I think this is one of the
reasons there's so much bad software in the world: too many of the
people who could make \emph{good} user interfaces, and elicit real
requirements from customers, and design programs that would actually
meet those needs, are choosing to do other things with their lives.

This isn't going to be easy to fix, but team programming projects give
you a chance to start.  Don't monopolize the discussion, no matter how
many bright ideas you think you have; hear your teammates out, keep
\emph{their} schedules in mind when you're thinking about leaving your
share of the work 'til the last moment, don't say anything in email
that you wouldn't say to someone's face\footnote{Many studies have
shown that people tend to be more abrupt or confrontational in email
than they are in person.  If you aren't careful, this can easily lead
to a vicious circle that only ends when one person or another is
compared to Hitler{\ldots}}, and remember that ``please'' and ``thank
you'' are always stylish.

%======================================================================
\chaplbl{Process}{s:process}
%======================================================================

A \defterm{development process} is a set of guidelines that a team
follows when building a piece of software.  Dozens have been described
over the last thirty-five years; most have passionate advocates, and
equally passionate detractors.

Generally, I'm sceptical of the claims made about processes, partly
because many fly in the face of my personal experience, but also
because the Scot in me instinctively mistrusts anything that's hyped
as hard as most processes have been.  Most importantly, I don't think
that the practices that make up a particular process are the real
reason they're successful, because teams that adopt diametrically
opposed methodologies both see productivity improve.

One possible explanation is that common practice is the worst of all
possible worlds, and any change at all would be an improvement.
(There are days when I believe this.)  A more likely explanation is
that what really matters is \emph{deciding that you want to be a
better programmer}.  If you make a sincere commitment to that, then
exactly how you get there is a detail.  It's kind of like dieting:
Atkins, South Beach, macrobiotic, seasonal, or fruitarian is secondary
to being sincere about eating better and exercising more.

%----------------------------------------------------------------------
\seclbl{Daily Routine}{s:process-daily}
%----------------------------------------------------------------------

Before describing the two development processes you're most likely to
encounter in courses, I'd like to talk for a moment about what your
day-to-day routine should look like.  As I said above, this ``micro
process'' is pretty much the same no matter what ``macro process'' you
follow.

First, get your tooling in place (\chapref{s:tooling}).  This is just
as important as setting up a development environment in the first
place.  If some team members are using Make from the command line,
while others are building inside an IDE, or if one person is
automating tests with shell scripts, while another is using Python,
you will lose precious time to duplication and contradiction.

Once that's done, establish a routine.  ``A little every day'' is
great in theory, but when you're juggling four or five courses, it
often doesn't work in practice.  What's more important is to set aside
big blocks of time (so that your flow isn't interrupted), and to be
systematic in those blocks.  Here's an example:

\begin{itemize}

  \item 3:00 p.m.: you have two hours to spend on your project, so you
  launch \url{Eclipse} and do a \url{Subversion}
  update. Hm{\ldots}your teammates have changed 17 files since the
  meeting two days ago.

  \item 3:05 p.m.: you log in to \url{DrProject}\footnote{Or Trac, or
  Google Code, or whatever portal your team is using---see
  \secref{s:tooling-portal} for more about these.} and look at the
  event log.  Five tickets have been closed, but eight new ones have
  been created, three of which are assigned to you.  Looks like the
  file parser you wrote last week doesn't handle the ``clarification''
  the prof posted on Monday.  You start writing unit tests to check
  the things that are breaking.

  \item 3:25 p.m.: you have added twelve new file parsing tests to the
  project's test suite.  Eleven currently fail the way you expected;
  the twelfth triggers an assertion in a data structure one of your
  teammates built.  You file a ticket with a reference to the test
  case, check the tests in, and start fixing your code.

  \item 4:00 p.m.: the eleven tests whose failure was your fault now
  pass, so you check in your fixes and close the tickets.  You're
  careful to refer to the changeset that contains the fix in your
  comments when you close the tickets, and to the tickets in the
  comment on your changeset; it only takes a second to type in this
  information, and it makes it much easier for your teammates to keep
  track of what you've done.  You then take a five-minute break to
  check email; when you're done, you close your mail client (since
  you've learned the hard way that you can't resist looking at new
  messages if you know they're there).

  \item Now you can start work on the new feature you want to add
  (which translates part of the program's internal data structure into
  a blob of XML to send to a web server).  You have an hour less to do
  this than you originally planned, but that's OK: by fixing bugs
  first, you've avoided the all-too-common situation of only half the
  code working when the project is ``done''.  As with bug fixes, you
  start by writing some test cases, which help you think through the
  details of the two new interfaces and five new classes you're going
  to add.

  \item 4:20 p.m.: after rewriting your test cases a couple of times,
  you're happy with the API for the new feature.  Time to start
  coding?  Not quite: with only 40 minutes to go, you know you won't
  finish it today.  Instead, you decide to write the two interfaces in
  full, along with their Javadoc, to capture the thinking you've just
  done.  You will then write stubs of the new classes that implement
  those interfaces, all of whose methods will return 0 or \code{null}.
  These placeholders let you add calls to the classes and check that
  everything still compiles.

  \item 4:45 p.m.: having checked everything in, you send a short
  email to the project list to tell your teammates what you've done.
  You then reward yourself by checking email and reading a couple of
  blog postings about how bad the Maple Leafs' offensive lineup is
  this year.

\end{itemize}

Three sessions like that a week, from each person on the project, plus
a single one-hour team meeting, and you'll be in great shape.

%----------------------------------------------------------------------
\seclbl{Agile vs. Sturdy}{s:process-agile-sturdy}
%----------------------------------------------------------------------

Broadly speaking, modern software development processes can be divided
into two camps.  In order to understand the differences between them,
and in fact why both exist at all, take a look at the ``Boehm Curve''
in \figref{f:boehm-curve}, which shows the effort required to fix a
bug based on when it is caught.

\begin{figure}
  \FIXME{Need Boehm Curve figure.}
  \caplbl{Error Correction Costs}{f:boehm-curve}
\end{figure}

Boehm's original work in the 1970s showed that fixing bugs became
exponentially more expensive as you moved later and later in the
development cycle.  Better tools and vastly more powerful computers
have flattened this curve over the past thirty years, but it is still
more expensive to fix things later than earlier.

Development teams deal with this in three ways. The first is to ignore
it.  If you're being paid a steady salary by a company that can
survive delays and cost overruns in your project, or if you're willing
to give up your evenings and weekends, then{\ldots}well, even then
this strategy doesn't make much sense, but a lot of people adopt it
anyway.

The second strategy is to do a lot of planning and design to catch as
many errors as possible during the early phases of the project.  This
is the classical engineering strategy; when you're building a dam, and
fixing mistakes means moving several million tons of earth around,
it's the only one that makes sense.  Until recently, most academic
software engineering research focused on this strategy as well, which
meant it was what most courses and textbooks taught.  I call this
approach \defterm{sturdy development}: it may feel a little slow at
times, but it can carry a lot of weight.

The third strategy emerged in the late 1990s under the name
\defterm{agile development}.  It starts from three related premises:

\begin{enumerate}

  \item You \emph{can't} plan a software project very far in advance
  because requirements and technology are constantly changing.

  \item You \emph{shouldn't} plan very far in advance because your
  customers can't know what they actually want until they see
  something working.

  \item You can \emph{afford} not to lock yourself into a long-term
  plan because software is much more malleable than concrete or steel.

\end{enumerate}

The best response, say agile's advocates, is to move in many small
steps, rather than a few large ones.  \figref{f:dev-process} shows the
difference: the traditional approach tries to flatten the error cost
curve by taking better aim at the outset, while agile development
re-aims more frequently so that the curve never climbs too high.

\begin{figure}
  \FIXME{Figure showing development processes.}
  \caplbl{Development Processes}{f:dev-process}
\end{figure}

That's the theory.  In practice, the differences between the two camps
are a lot smaller than their rhetoric would lead you to believe.
Regardless of what process they're officially using, most developers
do some long-range planning at the start of the project (if only
because customers are usually not willing to sign a blank check), and
then revise their plans and aims as they go along.

Which process makes the most sense for an undergraduate course
project?  Odds are, the question won't even come up: your instructor
will probably tell you to follow the analyze-design-code-test-deploy
cycle of the classical (sturdy) model, or to work in two- or
three-week agile iterations.  I usually use the former in courses,
since (a) you're very likely to encounter it after you graduate, (b)
it gives you more chance to hone your planning and scheduling skills
(\secref{s:process-plansched}), and (c) close interaction with
customers is a central tenet of most agile processes, but isn't really
possible in a classroom setting.

Since your project has to fit in one or two terms, you'll probably be
asked to go around the loop once or twice, which in turn determines
how much you'll be expected to deliver in each iteration.  This is
called \defterm{time boxing}: you specify how long a cycle will last,
then see how much work you can fit into that interval.  The
alternative is \defterm{feature boxing}, i.e., decide what you want to
do, then build a schedule that gives you enough time to do it.  Most
people believe that time boxing works better, since it encourages
developers to take smaller steps, and allows them to give customers
more frequent demos (which serve as course corrections).

%----------------------------------------------------------------------
\seclbl{Planning and Scheduling}{s:process-plansched}
%----------------------------------------------------------------------

If you're going to spend three days driving across the country, it
makes sense to spend half an hour figuring out a good route.  Equally,
if you're going to spend several months building a complex piece of
software, \emph{and you know what the final result is supposed to look
like}, it makes sense to spend some time figuring out what you're
going to do, and how long it ought to take.  This is called
\defterm{scheduling}; since most students have never had to do it,
many find it the most valuable part of their first project course.  In
order to explain how to go about it, I need to describe two important
roles in real software projects: the product manager, and the project
manager.

The \defterm{product manager} is the person who owns the spec.
Typically, while developers are building Version N, she is talking to
customers in order to find out what should go into Version N+1.  She
never, never asks them what features they want, because if she does,
what she'll get is a mish-mash of conversations overheard in frequent
flyer lounges, and buzzwords plucked from the lead paragraphs of
recent Slashdot articles.

Instead, she asks, ``What can't you do right now that you want to?'',
``What do you find irritating in the current product?'', and, ``Why
are you buying our competitor's software instead of ours?''  She then
translates the answers into a list of features to be considered for
Version N+1.  The product manager usually also talks to developers to
find out what \emph{they} don't like about the current software, and
adds their wishes to the pile.  Typically, these are things like
``refactor the persistence layer'', ``clean up the build'', and
``upgrade to the latest version of Java''.

So, it's Monday morning.  Version N shipped last
Thursday\footnote{Never, ever ship on Friday.}; the team has had a
weekend to catch its collective breath, and is ready to start work
once again.  (If people are so burned out from the previous round that
they need a whole week to recover, go back and re-read
\secref{s:important-crunch}.)  At this point, the product manager
divides up the list of desired features, and assigns them to the
developers.  Each developer then has some time---typically a few days
to a couple of weeks---to do a little research, write some throwaway
prototype code, and most importantly \emph{think}.  How could this
feature be implemented?  Is there a quick-and-dirty alternative that
would take a tenth the time, but only deliver half of what was asked
for?  What impact will each alternative have on the build?  On
deployment?  How will the feature be tested?  And so on.

This process is called \defterm{analysis and estimation}, or ``A\&E''.
The result is a short document, typically 2--10 pages long.  There's
no set form for these, but they usually include whatever background
information a well-informed developer is unlikely to already know, a
discussion of the alternatives, lessons learned from any prototyping
that was done, and most importantly, an estimate of how much time
would be needed to build each alternative.  This time includes
estimates from QA (for testing), the technical writer (for
documenting), the people responsible for the build and creating the
installer, and so on.

So now it's Monday morning again.  Three weeks have gone by, and all
the A\&E's are done.  When the time estimates are totaled, they come
to 700 developer-days.  Unfortunately, there are only 240 available:
the size of the team is fixed, and the next release has to be
available in May.  \emph{This is normal.} There is \emph{never} enough
time to add everything that everyone wants to a piece of software, and
even if there was, it probably shouldn't be done anyway.

What you do now is find a large whiteboard and draw a $3{\times}3$
grid on it.  The X axis is labeled ``effort'', the Y axis,
``importance'', and each is divided into ``high'', ``medium'', and
``low''\footnote{Finer-grained divisions, such as a 1--10 scale, add
no value: nobody has an algorithm for distinguishing priority 6 items
from priority 7 items, and anyway, the grid is just to get
conversation going.}.

Now, write each feature's name on a yellow sticky note, and put it on
the grid.  (Or, if you don't mind the smell of felt pens, write each
feature's number in the appropriate grid cell.)  You should wind up
with something like \figref{f:schedule-grid}.

\begin{figure}
  \FIXME{Need scheduling grid figure.}
  \caplbl{Effort vs. Priority.}{f:schedule-grid}
\end{figure}

You can probably guess what happens next.  First, you throw away the
high-effort, low-importance items in the bottom-right three
cells. Next, you start assembling the other items into a schedule,
starting with the upper-left corner.  These are the things that will
give the highest return on invested time; more importantly, starting
with these means that when something goes wrong\footnote{Something
\emph{always} goes wrong}, the team will still have delivered
something useful.

The items on the diagonal are the ones that have to be argued
over. Should the team tackle Feature 14 (high effort, high
importance), or Features 18, 19, and 22 (individually lower
importance, but the same total effort)?  It can take several sessions
to sort this out; the most important thing is that the people involved
don't start playing ``Kirk and Scotty'' with the
estimates\footnote{This term comes from a frequent scene in the
original \emph{Star Trek} series.  Kirk: ``How long 'til the engines
are back on line?''  Scotty: ``Three days, captain.''  Kirk: ``I need
them in two minutes!''  Scotty: ``Och, all right.''}---if management
starts shaving developers' estimates, developers will start padding
those estimates in self-defense.  Since managers aren't stupid,
they'll shave the estimates even more, so developers will add even
more padding{\ldots}

The hardest step in this process for beginners is coming up with time
estimates for particular tasks.  How can you possibly guess how long
it will take to write a database persistence layer for some Java
classes if you've never used a persistence layer before?  There are
two answers:

\begin{enumerate}

  \item You're not expected to pull an number out of thin air (at
  least, not by managers who know what they're doing).  Instead, you
  should budget enough time to write some throwaway code, or download
  and mess around with an open source tool, in order to get a feel for
  it.

  \item You've had to learn other new technologies before, and then
  apply them in courses.  A guess based on that experience might be
  off by a factor of two or three, but it probably won't be off by a
  factor of ten.  Even if it is, it's better than no guess at all,
  provided everyone involved knows that it's a guess\footnote{You will
  meet people who will be very critical every time one of your
  estimates is wrong.  In my experience, they are no better at
  estimating than anyone else.  When you point this out to them, do so
  politely.}.

\end{enumerate}

Remember: the more estimating you do, the better you'll get, and the
better you are, the more you'll impress your first real boss.

%----------------------------------------------------------------------
\seclbl{Cutting Corners}{s:process-cutting-corners}
%----------------------------------------------------------------------

Contrary to popular belief, a schedule's primary purpose is \emph{not}
to tell you what you're supposed to be doing on any given day.
Instead, its purpose is to tell you when you should start cutting
corners.  Suppose, for example, that you have ten weeks in order to
accomplish some task.  Five weeks after you start, you've only done
the first four weeks' worth of work.  You have several options
\cite{b:rothman-manage-it}:

\begin{enumerate}

  \item Denial.  This is very popular, but doesn't actually solve the
  problem.

  \item Tell yourself that you'll just have to work harder, and start
  putting in evenings and weekends.  This is also very popular, but
  ultimately self-defeating.  When you're tired, the quality of your
  work goes down; any ground you gain by working 'til three a.m. you
  lose again to extra debugging and rewriting.

  \item Ask for more time.  Groups working in industry often do this
  (usually in combination with the previous solution), but it usually
  isn't an option in an academic setting.  Instructors have to submit
  marks at the end of the term; as far as the university is concerned,
  whatever hasn't been done by then might as well not be done at all.

  \item Cut corners, either by doing less testing (which is quickly
  self-defeating), or by updating the schedule to reflect the rate at
  which you're \emph{actually} working, and dropping features that you
  already know you won't be able to finish in time.

\end{enumerate}

Let's return to our example.  At the start of the project, you
believed it would take ten weeks.  You're now at week five through,
but you've done only the first four weeks' worth of work.  Looking at
it another way, your estimates for how long sub-tasks would take were
too optimistic by about a quarter.  You should therefore go back to
your schedule and add 1/4 to each task's estimate.  That inevitably
means that some of the things you originally planned to do now spill
off the end of your ten-week window.  That's OK; it's a shame you
won't get to them, but at least you know it now, and can start taking
action (like lowering your customer's expectations) well in advance of
delivery.

In the real world, these calculations are the responsibility of the
\defterm{project manager}.  Her job is to make sure everyone is doing
what they're supposed to be doing, to handle interruptions (there are
\emph{always} interruptions), and most importantly, to track the
team's progress.  After a few weeks, the project manager should
compare how much has actually been done with how much was supposed to
be done, and adjust plans accordingly.

Real customers will actually thank you for doing this, provided you do
it early.  ``I'm sorry, we're not going to have the frobnosticator for
May 1'' is OK on October 1, or even January 1, since it gives whoever
was counting on the frobnosticator time to make other plans.  It is
\emph{not} OK on April 30; neither is saying (or worse, not saying)
that it's ``done'', but full of bugs.  It's more problematic in
student projects, particularly if the instructor has specified the
full feature set needed for an A.  In that case, the best you can do
is ask which features are worth the fewest marks, and cut those.

Taking scheduling seriously is one of the things that distinguishes
good software development teams from bad ones.  It's unfortunate that
you'll only get to do it once or twice during your project course,
since you only really see the benefits with practice, but I hope that
even once will be enough to convince you that it's worth doing.

Which brings us to a pet peeve.  Engineering project management
textbooks often say that there's a tradeoff between schedule,
resources, and features: if you fix the number of people working on
something, and what features they're to produce, that determines the
schedule, and so on.  Some people in the software industry claim that
it's actually a four-way tradeoff, with ``quality'' as the fourth
attribute.  That's dreck: if a feature only works half the time,
\emph{it isn't done} (or it's only 50\% done), so treating quality as
an independent dimension is bafflegab.

%----------------------------------------------------------------------
\seclbl{Test-Driven Development}{s:process-tdd}
%----------------------------------------------------------------------

No matter what process you use, there's one technique you really,
really want to adopt: \defterm{test-driven development}, or TDD.  This
is best described by a little piece of pseudocode:

\begin{alltt}
while (not done):
    figure out what the next small step is
    write some tests to see whether it's working
    write the code that implements it
    debug until the tests pass
\end{alltt}

Yup: when you're using TDD, you write your tests \emph{before} you
write your code.  This seems backward: the tests can't run, and
probably won't even compile, before the code is written, so what's the
point of creating them?  However, many programmers have found that
writing tests first reduces the total time required to get code
working.  The reasons are:

\begin{enumerate}

  \item Writing tests forces you to clarify exactly what your code is
  supposed to do.  It's easy to say, ``The method will return the name
  of the device that's supposed to handle the I/O request,'' but as
  exercises like the one in \cite{b:ernst-chapin-groupthink}
  demonstrate, every developer will interpret that ``specification''
  differently.

  \item Most people don't want to find problems in their code---in
  fact, when programmers test their own code, they subconsciously shy
  away from testing the parts that are most problematic.  If you write
  your tests first, though, you don't already have a psychological
  commitment to the ``correctness'' of the code, so your tests are
  more likely to be honest.

  \item TDD gives you goalposts: when all your tests pass, you're done
  writing that feature, and can move on to the next problem.  This
  provides some rhythm to your working day (tests are red, code code
  code, tests are green, get up and stretch, repeat), and discourages
  gold plating (i.e., adding more and more features that you're
  probably never going to need).

\end{enumerate}

%----------------------------------------------------------------------
\FIXME{\seclbl{Code Reviews}{s:process-codereview}}
%----------------------------------------------------------------------

%----------------------------------------------------------------------
\FIXME{\seclbl{What To Do When Things Go Wrong}{s:process-disaster}}
%----------------------------------------------------------------------

%======================================================================
\chaplbl{Tooling}{s:tooling}
%======================================================================

A carpenter shows up to put an extension on your house, and all he's
brought with him is a hammer and a Swiss army knife.  How confident
are you that he'll be able to do the job?

A programmer shows up to fix a couple of memory leaks and add a new
splash screen to your application, and all she's going to use are a
plain-text editor and a compiler.  Are you any more confident in her
ability to do the job in a reasonable time?

Tools don't just help us do things more easily; they shape what we
consider possible, and encourage some working practices while
discouraging others.  They also advertise how seriously we take our
craft: people who want to be good at something are willing to invest
time in learning how to do it better, and in programming, that means
mastering new tools and the practices that go with them.

I actually believe that processes are more important than tools, but
that's because I know how to use whatever tools I have at hand to
support the working practices I think are most productive.  However, I
tell students that tools are more important than processes because
tools are more tangible: it's easier to tell if someone is using
version control or ticketing than it is to tell if they're designing
or estimating sensibly.

So here, in more-or-less priority order, are the tools you should use
in your project.

%----------------------------------------------------------------------
\seclbl{Version Control}{s:tooling-versioning}
%----------------------------------------------------------------------

Version control is the collective memory of the project.  It's what
lets you move files from one machine to another without clobbering
stuff you just spent three hours writing, and without worrying about
whether you forgot an all-important file.  It's also what lets you
undo your mistakes: if you spend an hour or two going down the wrong
path, and want to get back to where you were, version control lets you
do it reliably with a single command.  And if all that wasn't enough,
version control lets you keep track of who did what, so that you can
allocate credit and blame where they're due.

Dozens of version control systems exist.  For many years, \url{CVS}
was the workhorse of the open source world, and very popular in
commercial projects as well.  It has now largely been replaced by
\url{Subversion}, which fixes many of CVS's flaws (while introducing a
few minor ones of its own).  Alternatively, if you have money to
spend, there's \url{Perforce}, which is my personal favorite.

These three, and most others, all have the same general architecture.
The master copy of the project resides in a \defterm{repository},
which is located on a server
(\figref{f:version-control-architecture}).  No one ever edits the
repository files directly; instead, each member of the team keeps a
\defterm{working copy} on her machine.  When she wants to share her
work with her teammates, she \defterm{commits} her files, which copies
any changes she has made to the repository.  She can also
\defterm{update} her working copy, which copies changes other people
have committed to the repository into her working copy.

\begin{figure}
  \FIXME{Image of version control architecture}
  \caplbl{Architecture of a Version Control System.}{f:version-control-architecture}
\end{figure}

What happens when two or more people change the same file at the same
time?  One or the other will commit first; her changes will go into
the repository.  When the second person tries to commit, though, the
version control system notices the \defterm{conflict}, and gives him
three options:

\begin{enumerate}

  \item Throw away his work.

  \item Throw away what his teammate has done.

  \item \defterm{Merge} the changes, i.e., go through the conflicts
  and decide what to keep or rewrite.

\end{enumerate}

Version control means never having to say you're sorry: since the
repository keeps a record of all the changes ever checked in, any
developer who wants to can \defterm{revert} to earlier versions of
files.

Using a version control system is one of the things that distinguishes
professional programmers from amateurs.  Yes, you can share files by
mailing them back and forth, or copying them from one laptop to
another over wireless or with a USB stick.  But why would you?  A
version control system will do all the hard work for you, and get it
right every time.

The only drawback of version control systems is that they work best
with plain text files---most of them don't really know what to do with
binary files, such as sound clips, images, or \url{Microsoft Word}
documents.  When changes have been made to a Java source file, for
example, \url{Subversion} can find and display the lines that have
been edited.  When you and your teammates all edit the Word version of
your final report during the same boring lecture, on the other hand,
all \url{Subversion} can do is tell you that the files have been
changed---it can't find and highlight the changes for you.  This isn't
really its fault: there are hundreds of different binary file formats,
and most don't come with tools for diffing (i.e., finding differences)
or merging.  Still, programmers' heavy use of version control is one
of the things that keeps them in the ASCII dark ages.

\seclbl{Editor}{s:tooling-editor}

The next most important tool after a version control system is your
editor.  There are literally thousands to choose from; if you want a
plain text editor, your choices range from the very small (such as
Pico, which is included in most Linux installations) to the very large
(like \url{Emacs}, whose name doesn't actually stand for ``eighty
megabytes and constantly swapping'', and which isn't actually a
Lisp-based operating system in disguise).  There are also editors that
understand the syntax of particular file formats, and can
automatically indent text, complete phrases, and colorize the stuff
you're typing: \url{JEdit} for Java, \url{Amaya} for HTML, and many
others.  Finally, there are WYSIWYG tools like \url{Microsoft Word}
and \url{OpenOffice}; these usually \emph{can't} be used for
programming, since they insert non-ASCII characters and formatting
information in files (even files that look unformatted).

You probably already have a favorite editor.  If you're like most
programmers, you will change jobs, languages, operating systems, and
nationality before you'll switch to another, because it's taken weeks
or months for your hands to master the current one.  However, if your
editor doesn't pass the following tests, switching now will save you
enough time and grief in the future to make the temporary loss of
productivity worthwhile:

\begin{enumerate}

  \item \emph{Is it kind to your wrists?} I was an Emacs power user
  for many years, and have paid a heavy price for it: I can't type for
  more than half an hour now before my hands start to hurt from all
  those control-key combinations and long reaches for the escape key.
  If ergonomics was a standard part of the undergraduate curriculum,
  programming editors would probably be used as examples of bad
  design.

  \item \emph{Is it portable?} I'm writing this on Windows; an hour
  from now I'll be using my Mac laptop, and on Monday I'll be back on
  a Linux machine at work.  I don't know what I'll be using next year;
  what I'm sure of is that I won't want to have to retrain my hands to
  use it.  The moral is, pick an editor that's portable.  In practice,
  that means one that is open source: you don't want to have to trust
  other people to care about the platforms you do.

  \item \emph{Is it syntax-aware?} Human beings shouldn't have to
  indent code, or count parentheses to make sure they have closed all
  the ones they opened.  They equally shouldn't have to type every
  character in the name of every function or method they call: their
  editor should do these things for them.  This won't just save wear
  and tear on your wrists: letting the machine do it will make the
  text you create more uniform, and hence more readable.

  \item \emph{Is it programmable?} Just like spreadsheets, games, and
  other applications, editors are built out of functions.  Good ones
  let you call those functions yourself, so that you can write small
  programs (usually called ``macros'') to automate common
  operations. For example, back in my Emacs power user days, I could
  type escape-X, ``cfl'' (for ``C for loop''), ``i'', and ``N'', and
  my editor would insert:
\begin{alltt}
for (i=0; i<N; i++) \{
    _
\}
\end{alltt}

  \noindent (The underscore shows where the cursor was left.)  I also
  had macros to reformat the spacing in functions, keep track of how
  many lines of code I'd added or removed, and many other tasks.  I'll
  return to this idea in \secref{s:tooling-lang}; what's important is
  that as a programmer, you have the skills to make your tools do more
  than their creators intended, so you should find tools that allow
  you to.

  \item \emph{Does it handle Unicode characters?} Most programmers
  don't speak English as a first language, and spell their names using
  symbols that aren't in the old 7-bit ASCII character set.
  Programming languages haven't caught up yet---they still insist on
  using \code{<=} instead of $\leq$, for example---but at the very
  least, you have to be able to edit data and documentation (including
  comments in code) that include $\theta$, $\pm$, and the
  like\footnote{See \cite{b:spolsky-unicode} for a developer-oriented
  introduction to character sets in general, and Unicode in
  particular}.

\end{enumerate}

%----------------------------------------------------------------------
\seclbl{Programming Language}{s:tooling-lang}
%----------------------------------------------------------------------

Programmers have fought religious wars\footnote{A religious war is one
in which combatants hold very strong opinions precisely because there
is no evidence to support either side.} over ``what's the best
programming language'' for as long as there have \emph{been}
programming languages.  In my experience, which one you use makes a
lot less difference than most people think{\ldots}

{\ldots}as long as you use the right one, that is.  Fifteen years ago,
there was a pretty clear tradeoff between how quickly you can get a
program running\footnote{Where ``running'' means ``running
correctly''.  If the program doesn't have to be correct, you can write
it in ten seconds or less in any language you like.}, and how fast was
when it ran.  Scripting languages like Perl optimized programmers'
time; low-level languages like C optimized the machine's.

Today, the balance has shifted in favor of higher-level languages.
One reason is that modern microprocessors are so complex that only a
handful of human beings can out-code optimizing compilers.  Another
reason is that just-in-time compilers and generational garbage
collection have made higher-level languages intrinsically faster.  The
biggest, though, is that the execution time of modern applications
depends less on squeezing cycles out of processors than it used to.
The bottleneck in a dynamic web site is almost always network latency
or the time required to perform database operations; your code
probably accounts for only a few percent of the total, so doubling or
tentupling its speed has less effect than you'd think.

People still argue the merits of statically-typed and
dynamically-typed languages, though.  Java vs. Python, C\# vs. Ruby,
mustard vs. ketchup{\ldots} I personally prefer the latter, but I
don't know of any hard evidence from empirical studies showing that
any is better.  In practice, you'll usually make this choice based on
what the instructor tells you to use, what you already know, and what
gives you access to libraries you need.

If you \emph{do} have a choice, keep in mind that dynamically-typed
interpreted languages (like Python, Ruby, Visual Basic, and Perl) are
better suited to building little tools and programming aides than
statically-typed compiled languages (like C++, Java, and C\#).  Since
multilingual projects are harder to manage than unilingual ones, this
ought to bias you in favor of the former.  On the other hand, there
are a lot more commercial-grade tools for the second group of
languages, and even today, a lot more documentation.

%----------------------------------------------------------------------
\seclbl{Builder}{s:tooling-builder}
%----------------------------------------------------------------------

No matter what language you use, you're going to need a builder---a
tool that will transform what you've typed into what you want to
deliver.  The best-known builder in the Unix world is \url{Make},
which was invented in 1975 by a summer intern at Bell Labs\footnote{He
went on to become a vice president of IBM, which shows how far a good
tool can take you.}.  In order to use \url{Make}, you create a
configuration file that specifies the dependencies between the files
in your project, and the commands needed to update them.  For example:

\begin{alltt}
game.exe : game.bc graphics.bc utils.bc
        tx -E -o game.exe game.bc graphics.bc utils.bc

\%.bc : \%.grace
        tx -C $<
\end{alltt}

\noindent tells \url{Make} that \code{game.exe} can't be built until
\code{game.bc}, \code{graphics.bc}, and \code{utils.bc} exist, and
that once they do, the way to create \code{game.exe} is to run the
\code{tx} compiler with several options.  Below that is a
\defterm{pattern rule} telling \url{Make} how to create any \code{.bc}
file from a \code{.grace} file with the same root name; the cryptic
expression \code{\$<} is \url{Make}'s way of saying ``the first thing
the target depends on''.

\url{Make} was invented to recompile programs, but it can be used for
a lot more.  Here, for example, is a configuration file that updates a
web site:

\begin{alltt}
SRC_DIR = ${HOME}/webstuff
DST_DST = /www/personal/gvwilson

SRC_FILES = $(wildcard ${SRC}/*.html) $(wildcard ${SRC}/*.png)
DST_FILES = $(subst ${SRC},${DST},${SRC_FILES})

all : ${DST_FILES}

${DST}/\%.html : ${SRC}/\%.html
        replace AUTHOR=''Greg Wilson'' DATE=''${DATE}'' $< $@

${DST}/\%.png : ${SRC}/\%.png
        cp $< $@
\end{alltt}

This says that the source files are all the \code{.html} pages and
\code{.png} images in my \code{webstuff} directory.  Whenever I change
an HTML page, I want the \code{AUTHOR} and \code{DATE} fields replaced
with appropriate values as the file is copied to my web site.  If a
PNG image changes, it should be copied over unchanged (since treating
the bytes in a PNG as ASCII characters will almost certainly result in
an unreadable image).

\url{Make} has been used by hundreds of thousands of programmers for
more than thirty years, but has some fundamental flaws.  The first, as
you can see, is its syntax.  The second is that it runs commands by
handing them over to whatever operating system it is running on, which
make portability a constant headache.  (Quick, should you use
\code{rm} or \code{del} to delete a file?)  Third, \url{Make} doesn't
have a debugger: the only way to track down problems in your build
configuration is to stare at the configuration file until little drops
of blood form on your forehead.

Newer builders like \url{Ant} try to fix the first two problems by
using XML for their configuration file syntax, and by providing a
library of commands for programmers to call (which \url{Ant} then
translates into operating system calls as necessary).  \url{Ant} is
now widely used in the Java world, and clones like \url{NAnt} are
popular as well, but its XML syntax is still pretty ugly, and it still
doesn't have a real debugger.

Now, I could live with ugly syntax---if Ie kan lurn Inglish speling,
Ie kan lurn eneething.  But the lack of a debugger is a never-ending
headache, because real build systems aren't just configured: they're
programmed.  Take the HTML notes for the course I'm currently
teaching, for example: at 341 lines, the Makefile that checks the
consistency of cross-references, makes sure all the bibliography
citations are in place, updates the license, and copies files to my
web site is more complex than many programs I've written.  Thinking of
it as a ``configuration'' file is a mistake: you \emph{have} to
approach system builds as a programming problem.  This means that
every build system eventually turns into a small programming language,
which is why James Duncan Davidson, the inventor of \url{Ant}, wrote
in 2004:

\begin{quotation}

  If I knew then what I know now, I would have tried using a real
  scripting language, such as JavaScript via the Rhino component or
  Python via JPython, with bindings to Java objects which implemented
  the functionality expressed in todays tasks. Then, there would be a
  first class way to express logic and we wouldn't be stuck with XML
  as a format that is too bulky for the way that people really want to
  use the tool.

\end{quotation}

The next generation of builders are therefore almost certainly going
to dispense with custom configuration file syntaxes, and be layered on
top of dynamic languages like Python and Ruby.  \url{SCons} and
\url{Rake} are examples of such a system: its users write their
``configurations'' as small Python or Ruby programs, making use of an
extensive support library that handles dependencies, invokes
appropriate compilers, and so on.  Debugging is still problematic, but
at least it's possible.

Whatever you choose (or are told to use), stick to the following
rules:

\begin{itemize}

  \item \emph{Pick something that plays nicely with your other tools.}
  Most Java editors and IDEs (\secref{s:tooling-ide}) integrate with
  \url{Ant}, so that you can (for example) jump directly to
  compilation errors when they occur.

  \item \emph{Always use the builder---never compile or copy things by
  hand.} This isn't just for efficiency's sake: if any of the twelve
  things you need to do to get your application up on your web site
  have to be done by hand, the odds are that you'll forget a crucial
  step right before your end-of-term demo, and wind up looking silly.

  \item \emph{Always use the builder---never compile or copy things by
  hand.} Yes, I know I'm repeating myself, but this time the reason is
  different.  If you do something by hand, one of your teammates might
  do it differently.  ``But it works on my machine!''  isn't something
  you want to hear an hour before a deadline{\ldots}

\end{itemize}

A good way to start using a builder is to create a ``version zero'' of
the project.  Set up the build and make sure it works even when there
isn't anything to compile, run, test, or copy.  Now add
something---anything.  Does the build still work?  If it does, you're
on your way.

Once you've got that, \emph{never check anything into version control
that breaks the build}.  This is one of the golden rules of working in
a team: if your code won't compile, or doesn't pass whatever automated
tests you have, then putting it into the repository means putting
every other person on your team into exactly the same broken state
you're in.  When you're working on your own, it's OK to use version
control as a way to transfer files from one machine to another, or as
a way to back things up at the end of the day.  Do \emph{not} carry
this habit over to teamwork.

%----------------------------------------------------------------------
\seclbl{Debugger}{s:tooling-debugger}
%----------------------------------------------------------------------

A \defterm{symbolic debugger} is a program that allows you to control
and inspect the execution of another program.  You can step through
the target program a line at a time, display the values of variables
or expressions, look at the call stack, or (my personal favorite) set
\defterm{breakpoints} to say ``pause the program when it reaches this
line'' (\figref{f:debugger}). Depending on the language you're using,
you may have to compile your program with certain options turned on to
make it debuggable, but that's a small price to pay for the hours or
days a debugger can save you when you're trying to track down a
problem.

\begin{figure}
  \FIXME{Screenshot of debugger.}
  \caplbl{Debugger in Action}{f:debugger}
\end{figure}

Some debuggers, like \url{GDB}, are standalone programs; others are
build into IDEs (\secref{s:tooling-ide}).  Both are better than adding
\code{print} statements to your program, recompiling it, and
re-running it, because:

\begin{itemize}

  \item adding \code{print} statements takes longer than clicking on a
  line and setting a breakpoint;

  \item adding \code{print} statements distorts the code you're
  debugging by moving things around in memory, altering the flow of
  control, and/or changing the timing of thread execution; and

  \item it's all too easy to make a mistake in the \code{print}
  statement---few things are as frustrating as wasting an afternoon
  debugging a problem, only to realize that the \code{print} statement
  you copied and pasted isn't displaying the values you thought it
  was.

\end{itemize}

A company I used to work for never hired people immediately.  Instead,
prospective employees were put on a three-month contract.  This gave
us a chance to see how well they worked, and them a chance to see if
they actually wanted to work with us.

Two things meant automatic disqualification in the assessment at the
end of those three months: checking broken code into version control,
and using \code{print} statements instead of a symbolic debugger.  The
first was justified because we didn't want to hire people who put
themselves ahead of their teammates.  The second was justified because
we didn't want to hire people who were too stupid or stubborn to
program efficiently.

Over the years, I've been surprised by how strongly some programmers
resist using a debugger.  The reason can't be the five or ten minutes
it takes to learn how to use one---that pays for itself almost
immediately.  The only explanation I've been able to come up with is
that some people \emph{enjoy} being inefficient.  Typing in
\code{print} statements and paging through screens of output lets them
feel like they're being productive, when in fact they're just being
busy (which isn't the same thing at all).  If your brain needs a break
(which it sometimes will), then take a break: stretch your legs, stare
out a window, practice your juggling, or do whatever else you can to
take your mind away from your problem for a few minutes.  Don't drag
out the process of finding and fixing your bug by using sloppy
technique just to let your brain idle for a while.

And by the way: if you're allowed to choose your teammates at the
start of the course, treat it like a job interview.  Ask the people
you think you might want to work with whether they use a debugger.  If
they say ``no'', ask yourself what impact that's going to have on your
grade in the course{\ldots}

%----------------------------------------------------------------------
\seclbl{IDE}{s:tooling-ide}
%----------------------------------------------------------------------

A smart editor, a build system, and a debugger, all talking to one
another: that's a pretty good description of an \defterm{integrated
development environment}, or IDE.  These were invented in the 1970s,
but didn't really catch on until Borland released Turbo Pascal in the
1980s\footnote{Its inventor, Anders Hejlsberg, went on to design C\#,
which also shows how far a good tool can take you.}.  Along with the
tools described above, modern IDEs usually include:

\begin{itemize}

  \item a \defterm{code browser} that displays an overview of the
  packages, classes, methods, and data in your program;

  \item a \defterm{GUI designer} that lets you build GUIs by dragging
  and dropping components;

  \item an \defterm{interactive prompt} so that you can type in
  expressions or call functions and see the results without having to
  start (or restart) your program;

  \item a \defterm{style checker} that can warn you when your code
  doesn't meet naming and indentation conventions;

  \item some \defterm{refactoring tools} to help you reorganize your
  code; and

  \item a \defterm{test runner} to display the results of tests, and
  let you jump directly to ones that have failed.

\end{itemize}

In short, an IDE is to programming what a well-equipped workbench is
to a carpenter.  The most popular one among open source developers is
undoubtedly \url{Eclipse} , which has hundreds of plugins of varying
quality to support database design, reverse engineering, a dozen
different programming languages, and more.  \url{Microsoft Visual
Studio} is still my personal favorite, largely because of how well its
debugger handles multithreaded programs; as of May 2007, the Express
Edition is still free.

There are dozens of others, any of which will make you more productive
than their disconnected counterparts.  Since most of these store
project data (including build instructions) in a proprietary format,
your team will do much better if you all adopt the same IDE.  This
will also let you help one another solve problems and share
plugins\footnote{Having to agree on \emph{which} IDE to use may be
another reason why some programmers resist adopting any IDE at all,
since they require even more investment to master than editors.}.

%----------------------------------------------------------------------
\seclbl{Ticketing}{s:tooling-ticketing}
%----------------------------------------------------------------------

You probably have a to-do list somewhere.  It might be scribbled in a
calendar or lab notebook, kept in a text file on your laptop, or in
your head; wherever and however you maintain it, it lists the things
you're supposed to do, when they're due, and (possibly) how urgent
they are.

At its simplest, a \defterm{ticketing system} is a shared to-do list.
Ticketing systems are also called \defterm{bug trackers}, because most
software projects use one to keep track of the bugs that developers
and users find.  These days, ticketing systems are almost invariably
web-based.  To create a new ticket, you enter a title and a short
description; the system then assigns it a unique serial number
(\figref{f:ticketing}).  You can usually also specify:

\begin{itemize}

  \item who is responsible for the ticket (e.g., who's supposed to fix
  the bug, or test the fix, or update the documentation);

  \item what kind of ticket it is (a bug report, a request for a new
  feature, a question to be answered, or some other task);

  \item how important it is; and

  \item when it's due.

\end{itemize}

\begin{figure}
  \FIXME{Screenshot of ticketing system}
  \caplbl{A Ticketing System in Action.}{f:ticketing}
\end{figure}

If version control keeps track of where your project has been, your
ticketing system keeps track of where you're going.  After version
control, ticketing is therefore the most essential part of a team
project.  Without it, you and your teammates will have to constantly
ask each other ``What are you working on?'', ``What am I supposed to
be working on?'', and ``Who was supposed to do that?''  Once you start
using one, on the other hand, it's easy to find out what the project's
status is: just look at the open tickets, and at those that have been
closed recently.  You can use this to create agendas for your status
meetings (\secref{s:important-meetings}), and to remind yourself what
you were doing three months ago when the time comes to write your
final report (\secref{s:wrapup-report}).

Of course, a ticketing system is only as useful as what you put into
it.  If you're describing a bug in a large application, you should
include enough information to allow someone\footnote{Possibly yourself
two weeks from now} to reproduce the problem, and someone else to
figure out how urgent the bug is, who should work on it, and what
other parts of the application might be affected by a fix.  This is
why industrial-strength ticketing systems like \url{Bugzilla} have
upwards of two dozen fields per ticket to record:

\begin{itemize}

  \item what version of the software you were using
  (\secref{s:design-numbering});

  \item what platform it was running on;

  \item what you did to make it crash;

  \item any data or configuration files the program relies on;

  \item whatever stack traces, error reports, or log messages the
  program produced (\secref{s:design-logging});

  \item its severity (i.e., how much damage the bug might do);

  \item its priority (how urgently the bug needs to be fixed); and

  \item other tickets that might be related.

\end{itemize}

This is a lot more information than student projects require.  In
addition, students are almost always working on several courses at
once, and it's common for students to have to put their team project
aside for a few days to work on assignments for other courses.  For
these reasons, I've found that most student teams won't actually use
anything more sophisticated than a web-base to-do list unless they're
forced to by the course's grading scheme.  In that case, most come
away with the impression that tickets are something you only use when
you have to, rather than a vital team coordination tool.

\seclbl{Other Ways to Communicate}{s:tooling-communicate}

Tickets are the best way to keep track of where you are, but there are
lots of other ways the team can and should communicate.  The most
popular is easily \emph{email}, which has been used to run projects
since the 1970s.  It brings content directly to people while allowing
everyone to deal with issues when it's convenient for them, and
supports long-running conversations.  Email really comes into its own,
though, when messages are routed through a central mailing list, so
that people don't have to remember to CC the other five people on
their team, and a shared archive can be created for later searching.
The second point is as important as the first: if you can't go back
and find out what was said a month ago---or, just as importantly, if
someone \emph{else} can't do that---you might as well not have said
it.

\emph{Wikis} seem like a good way to keep notes, create documentation,
and so on.  Their strengths are a syntax that's (a little) simpler
than HTML, and the fact that content is automatically and immediately
visible on the web.  In practice, you'll probably get as much mileage
out of a bunch of HTML pages under version control---you have to set
up a repository anyway, and version control systems are much better at
reconciling conflicts between concurrent authors than wikis.

\emph{Blogs}, on the other hand, have proven more useful.  One kind of
project blog consists of articles written by the team's members as a
journal of their progress.  This is most useful for people who are
watching the project from the outside, like instructors.

The second kind of blog is one created automatically by tools.  In
\url{DrProject}, for example, every project has a blog called its
\defterm{event log}.  Every time someone checks code into version
control, creates or closes a ticket, or sends email, an entry is added
to the event log.  This allows the project's members to see changes
scroll by in their usual blog reader, which is a handy way to keep
track of what their teammates are doing.

The problem with blogs, at least right now, is that the RSS
standard\footnote{Or ``standards'', since there are at least half a
dozen variations in use today.} that blogging relies on does not
provide for authentication: there's no uniform way for blog readers to
pass credentials like passwords to blog sites.  In practice, this
means that blogs have to be open for everyone to read.  This is OK for
open source projects, but it's problematic for students, since
instructors usually don't want Team A to be able to see what Team B is
doing, and vice versa.  Emerging standards like \url{OpenID} may
eventually solve this problem, but for now, per-project blogs are
something that instructors have to think about very carefully.

Finally, there's \emph{instant messaging}.  I realize it's the
communication medium of choice for all you hip young things, but I'm
not a fan:

\begin{enumerate}

  \item IM is the most effective method ever invented for disrupting
  the state of flow that is so essential to productivity
  (\secref{s:important-time}).

  \item Most chat systems don't provide ``always-on'' chat rooms
  (\url{IRC} being a notable exception), so every time you want to
  talk to all your teammates, you have to round them up.

  \item Most IM systems don't archive conversations in the way that
  mailing lists do, so participants have to save the chat on their
  personal machines, then upload it to the project's site.  In my
  experience, that's just enough trouble for most people to never get
  around to doing it{\ldots}

  \item IM conversations tend to be permanently out of phase: if you
  ask, ``Can we move on to the next item?'', and someone doesn't say
  either ``yes'' or ``no'', what usually happens is that you wait a
  minute, then move on, and then they pop up with a lengthy comment on
  the preceding item.

\end{enumerate}

I think these faults can all be fixed, but until they are---oh, who am
I kidding?  You're going to use IM no matter what I say.  If there's
more than two people in the conversation, follow the same rules you
would for a meeting.  In particular, post a summary of the
conversation to your project's web site, just as you would post
meeting minutes.  And if you want to figure out how to make IM a
productivity enhancer, please send me email: I'm always looking for
good graduate students.

\seclbl{Portals}{s:tooling-portal}

All of which brings us to project management portals, which do for
groupware what IDEs do for desktop tools.  The best-known by far is
\url{SourceForge}, which hosts over a hundred thousand open source
projects\footnote{Of which only a few percent are actually live at any
time.}, but there are many others to choose from, such as \url{Google
Code}.  A portal typically provides a read-only
view\footnote{Read-only because (a) giving the web server the ability
to overwrite content in the repository would be a huge security hole,
and (b) there's no point allowing people to write to the repository
unless you can think of a web-based interface for editing source code
that people will actually use.} of the project's version control
repository with a ticketing system, a wiki, mailing lists, blogs, and
other odds and ends.

Portals are attractive because setting up one system that does all of
these things is a lot less work than setting up one system for each.
In addition, each tool becomes more powerful when it can easily be
used with others: if tickets can easily link to change sets in version
control, which can link to wiki pages, which can link to email
messages, each piece of information becomes more valuable.

Most portals are either too heavyweight for undergraduate projects, or
lack features that undergraduate courses need\footnote{Like a
scripting API, so that instructors can file the same ticket against
two dozen projects in one step, or a ``roll up'' view that shows the
progress several projects are making side by side.}.  \url{Trac} is a
flawed exception: it does most of the things student teams want, but
can only handle one project per installation, and doesn't offer
mailing lists.  We forked\footnote{To \defterm{fork} a project means
to create a new version of it that will evolve independently (i.e., to
take a fork in the road).  Forking shouldn't be done lightly, since
the more projects there are, the less development and maintenance
effort can be put into each.} \url{Trac} in 2005 to create
\url{DrProject}, a portal that specifically addresses these needs; if
your instructor hasn't already picked something out for your course,
take a look at \code{http://www.drproject.org}.

%----------------------------------------------------------------------
\seclbl{The Next Level}{s:tooling-next}
%----------------------------------------------------------------------

You and your teammates could use many other tools to make yourselves
more productive.  Some aren't part of the standard undergraduate
curriculum yet, even though good developers have been relying on them
for a decade or more.  Others may be touched on, but only briefly, so
a quick recap won't hurt.

The first is a \emph{documentation generator} like \url{Javadoc}.
This is a compiler of a sort, but instead of translating source code
into something executable, it extracts information from
specially-formatted comments and strings, and turns it into
human-readable documentation.  The justification for this is that when
code and documentation are stored separately, programmers won't keep
the latter up to date.  Since ``rusty'' documentation can be worse
than no documentation at all, it makes a lot of sense to keep the
source of the documentation right beside the code\footnote{The most
advanced wrinkle on this idea is Donald Knuth's \defterm{literate
programming}, which holds that programs should be written in a rich
notation that combines mathematical symbols with programming
constructs, then compiled to produce human-readable and
machine-readable versions.  It's a great idea, and as Unicode becomes
more widespread, it may well catch on.  What's holding it back now is
that debugging such programs is hard, since the code that's actually
bears only a rough resemblance to what you actually typed in.  If
you're interested in graduate school, there's a great thesis waiting
to be written here{\ldots}}.  Many introductory courses require
students to document their packages, classes, and methods this way;
it's a good habit, and one you should cultivate.

Another tool you should be fanatical about is some kind of \emph{test
harness} that can re-run your tests for you at the push of a button.
I won't repeat the arguments in favor of test-driven development
(\secref{s:process-tdd}) here; suffice to say that while \emph{you}
won't ever make silly mistakes, your teammates undoubtedly will, and
testing is your best way to prevent them from sinking your project.

The most widely used test harness today is \url{JUnit}\footnote{The
first version of which was written by Erich Gamma on a flight across
the Atlantic, which just goes to show you how far you can go while
writing a great tool.}.  Programmers write tests as methods, and group
them together into classes.  \url{JUnit} uses \defterm{reflection} to
find and execute the tests, keeping track of how many pass, fail, or
encounter unexpected errors (which usually indicate that the test
itself is broken, rather than the code under test).  Every modern Java
IDE can run \url{JUnit} tests and display the results, typically with
a red bar if some tests are failing, or a green one if all have
passed.

Clones of \url{JUnit} exist for most major programming languages, as
do extensions of various kinds for testing web applications
(\url{HttpUnit}), databases (\url{SqlUnit}), and how systems behave
under heavy load (\url{JUnitScenario}).  Whatever your project is
building, there's probably a \url{JUnit} extension to help you.

Along with testing frameworks, \emph{style checkers} have become a lot
more popular since the turn of the century.  Early style checkers
looked at code to make sure that it obeyed formatting rules, such as
``no method can be longer than 100 lines'' or ``class names must be
written in CamelCase''.  Today's, like \url{PMD} and \url{CheckStyle},
can do a lot more: they can find code that is never called, parameters
that are never used, duplicated code that could be factored out, and a
lot more.

Style checkers are more properly called \defterm{static analysis}
tools, since they work by parsing the source code for your programs
and looking for patterns that might indicate problems.  Compilers also
do a lot of static analysis\footnote{It's hard to do static analysis
for dynamic languages like Python and Ruby, which is one of the
reasons why compiled languages like C++, Java, and C\# are still more
popular for very large projects.}; the non-fatal warnings they produce
are a lot more useful than many students realize, and a ``zero
warnings'' policy can prevent a lot of subtle bugs.

Another class of tools uses \defterm{dynamic analysis}: they watch
your program run, and look for things like memory leaks, or
inconsistent locking that might lead to deadlocks or race conditions.
\url{FindBugs} is the best-known in the Java world; the \url{Valgrind}
toolset is a lifesaver if you're using C or C++.

All of these tools will do a lot more for you if you adopt some kind
of \emph{continuous integration} system, such as \url{CruiseControl}
or \url{BuildBot}.  These can be set up to run either at regular
intervals (say, every hour, or a three a.m.), or every time someone
checks into version control (which I find more useful).  Each time
they run, they check a fresh copy of the project out of version
control, build it, re-run all the tests, and post the results to the
project's blog, web site, and mailing list.  This acts as a
``heartbeat'' for the project: as soon as anything goes wrong,
everyone knows.  It also encourages good development practices: if
someone checks something in that doesn't compile, run, or pass the
project's tests, everyone will know very quickly.  Funnily enough,
after the system has shamed you a couple of times, you'll stop
checking in broken code{\ldots}

Real development projects rely on a lot of other tools as well:
schedule builders like \url{Microsoft Project}, requirements tracing
tools, visual editors for GUIs and class diagrams, and so on.  Most
are bigger hammers than undergraduate projects really require (except
possibly the GUI editors), so I'd like to close this section by asking
you to invest some time in something else: scripting.  Good
programmers don't just use tools, they build them.  I have dozens of
small programs in my \code{tools} directory that do things like update
my working copies of all the projects I'm involved in\footnote{Eleven
at present, though the number varies from term to term.} or check
whether the links to Amazon.com in my course notes are still valid.
Anything worth doing repeatedly is worth automating; if you and your
teammates find yourselves typing in the same commands over and over
again, \emph{write a program to do it for you}.  And please, use a
language like Python or Ruby rather than Java or C\#: the ``try it and
see'' nature of the former is a lot better suited to one-of-a-kind
scripts than the latter's type checking and compilation.

%----------------------------------------------------------------------
\seclbl{You May Also Be Interested In{\ldots}}{s:tooling-other}
%----------------------------------------------------------------------

A complete working environment needs more than just software.
Unfortunately, most university labs seemed designed to make everything
below difficult or impossible to achieve.

\begin{itemize}

  \item \emph{Peace and quiet.} Study after study has proved that this
  has more impact on productivity than a fast network, a fat disk, or
  caffeine, but most workplaces are still too crowded, too noisy, and
  filled with too many interrupts.  As mentioned in
  \secref{s:important-time}, it takes most people ten minutes to get
  back into a state of flow after being distracted, which means that
  half a dozen interruptions per hour effectively renders someone zero
  percent effective.  I know people say, ``If I can't overhear what
  other people are talking about, I might miss something important,''
  but that only applies if the only people you're overhearing are
  members of your own team (and even then, it's a dubious claim).

  \item \emph{Comfortable seating.} A good chair with a firm back
  costs one fifth of what a mid-range PC does.  A full-sized keyboard
  (I have large hands---most laptop keyboards force me to bend my
  wrists uncomfortably) costs fifty dollars, and a lamp with a
  soft-light bulb is another forty.  The combination doesn't just let
  me program longer each day; it also helps ensure that I'll still be
  able to program five or ten years from now without chronic back and
  wrist pain.  Compare this with what's in most computer labs: their
  lighting gives glare without illumination, the dark desktops make
  the optical mice jerky, and the low-budget chairs are guaranteed to
  make your lower back ache after an hour.  In short, they look like
  the kind of places that get full-page spreads in architectural
  magazines; as \cite{b:brand-how-buildings-learn} points out, those
  are rarely comfortable places to work.

  \item \emph{A pad of gridded paper and several ballpoint pens.}  I
  often make notes for myself when programming, or draw box-and-arrow
  diagrams of my data structures when debugging.  I used to keep an
  editor open in a background window to do the former, but when my
  wrists started acting up, I discovered that taking my hands away
  from the keyboard for a few moments to scribble something down
  provided welcome relief.  I also quickly discovered that the odds of
  me being able to read my own notes the next day rose dramatically if
  I used gridded paper to line them up.

  \item \emph{A heavy mug for coffee or tea.} I don't know why, but a
  styrofoam cup, or a normal teacup, just isn't as satisfying as a
  little hand-sized ceramic boulder.  Maybe it satisfies my
  subconscious Neanderthal urge to club my computer to death when it
  misbehaves{\ldots}

  \item \emph{A rubber duck.} One of computing's many apocryphal
  stories holds that someone---Brian Kernighan, maybe, or Dennis
  Ritchie---keeps a rubber duck next to his computer.  Whenever a bug
  takes more than a few minutes to track down, he puts the duck on his
  desk and explains the problem to it.  Why?  Because speaking out
  loud forces you to marshal your thoughts, which in turn highlights
  any contradictions or missed steps that you hadn't noticed while
  everything was just swirling around inside your head.

  \item \emph{A squirt bottle of glass cleaner and a box of kleenex.}
  I can't stand smears on my screen.  They drive me nuts.  Whenever
  I'm showing something to someone, and they actually \emph{touch my
  screen} instead of just pointing, I have another Neanderthal
  fantasy, except this time it's not subconscious{\ldots}

  \item \emph{A chess set}, or a deck of cards, or some juggling
  balls.  I'm a very bad chess player.  Luckily, so are most people,
  so it's usually possible to find someone at my level for a
  ten-minute game at lunch.  Other programmers I know play euchre, or
  knit---a programmers' ``stitch and bitch'' session can be
  jaw-dropping to listen to.  Few people can focus for more than a few
  hours before their productivity drops; it's better to acknowledge
  this, and take a break in the middle of the day, than to say,
  ``Must{\ldots} keep{\ldots} coding{\ldots}'' and produce garbage
  that just has to be rewritten later.

  \item \emph{Books.} You can find a lot on-line, but it's hard to
  google with your feet up on your desk, and even harder to fold down
  the corners on web pages.  When I want API documentation, I use the
  web; when I want a tutorial, I still prefer the printed page.  Right
  now, for example, I have \cite{b:berkun-art-proj-mgmt},
  \cite{b:doar-practical-dev-env},
  \cite{b:fogel-producing-open-source}, and
  \cite{b:ely-marmot-understanding-offices} within reach.

  \item \emph{Running shoes.} Back when I was a part-time grad
  student, I had a settled routine: I brought three sets of gym gear
  to the office at the start of the week, worked out at lunchtime on
  Monday, Wednesday, and Friday, and took my stuff home at the end of
  the week.  After two months of this, I came in to find that my
  co-workers had hung a little chandelier made of air fresheners over
  my desk.  Since then, I've rented a locker at the gym, but I still
  try to get some exercise several times a week---it helps my
  concentration and stamina a lot more than any amount of coffee..

  \item \emph{Pictures.} Ah, the nesting instinct.  Everyone wants to
  feel at home; everyone wants to make wherever they are uniquely
  theirs.  I hang a few postcards on the wall wherever I work, along
  with a photograph of my wife and daughter taken ten hours after she
  was born (my daughter, that is), just to remind me what's really
  important.

\end{itemize}

%======================================================================
\chaplbl{Design}{s:design}
%======================================================================

Building large programs with other people is different from building
small programs on your own.  This section describes a few of the
things that you'll want to do in the former case that might not crop
up in your regular classes.

I should confess up front that I can't tell you how to design
software.  I don't know anyone who can, either.  I can \emph{show} you
by working through examples on a whiteboard, asking rhetorical
questions, and setting problems for you to think about, but that
doesn't translate well to print.  If you can talk a handful of good
software designers into letting themselves be videotaped as they work
through problems on a whiteboard, please let me know---I'm sure I'd
learn a lot by watching them.

%----------------------------------------------------------------------
\seclbl{Describing Designs}{s:design-describe}
%----------------------------------------------------------------------

I can, however, tell you a little about how to describe designs.  If
you watch experienced developers drawing on the whiteboard as they're
talking to one another, you'll generally see them sketching the
following:

\begin{itemize}

  \item \emph{Data structures}.  These are blob-and-arrow pictures of
  the objects and containers that make up the program, and the
  references that stitch them together.  The more experience someone
  has, the fewer of these they need to draw, but everyone falls back
  on them eventually (particularly during difficult debugging
  sessions).

  \item \emph{Schemas} or \emph{data models}.  These can be fairly
  literal pictures of the tables in a database, possibly augmented
  with arrows to show what's a foreign key for what, or
  entity-relationship diagrams that show the things the system stores,
  and the relationships between them.

  \item The \defterm{conceptual architecture} of the system.  This is
  the most important diagram of all, since it's the ``big picture''
  view of how everything in the system fits together.  It's also the
  least constrained, since it can include everything from specific
  sections of configuration files to class hierarchies to replicated
  web servers.  I'll talk more about conceptual architectures below.

  \item The system's \defterm{physical architecture}, which is the
  files, processes, sockets, database tables, etc., that make it up.
  In most cases, this consists of a bunch of boxes representing the
  machines the application's components run on, trees showing files
  and directories, and circles showing running processes.  A lot of
  this stuff can show up in the conceptual architecture as well.

  \item The \defterm{workflow architecture}, which shows how users
  accomplish the things they want to do.  This is almost always drawn
  as a finite state machine.  In the web world, it is often called a
  \defterm{navigation diagram} or \defterm{roadmap}; each blob
  represents a page, and the arrows connecting them show how users can
  navigate from one page to another.

\end{itemize}

With the exception of schemas and data models, all these diagrams
consist of \defterm{components} and \defterm{connectors}, i.e., things
and the relationships between them.  In a physical architecture
diagram, for example, the components represent machines, processes,
and files, and the connectors represent sockets and the
``reads/writes'' relationship for files.

The most important diagram is the conceptual architecture, which is
the ``big picture'' view of how the most important pieces of the
system relate to one another.  What qualifies as ``important'' depends
on what aspect(s) of the system you're currently concerned with.  If
I'm trying to explain a bug that only arises when the application is
configured incorrectly, I might draw its configuration files, and the
database tables that store user preferences, but leave out the
password database and log files entirely.  If we're trying to figure
out a better load balancing strategy, on the other hand, I would draw
most of what would go into a physical architecture diagram, plus just
enough of the class inheritance hierarchy to show how the servers will
load user request handlers dynamically.

The goal of these diagrams is always to help your readers, listeners,
or viewers (including yourself) understand enough of the system to be
able to decide what to do next.  This is why I'm not a fan of the
\defterm{Unified Modeling Language} (UML).  UML defines over a dozen
different types of diagrams for showing the relationships between
classes, the order in which things happen when methods are invoked,
the states a system goes through when performing an action, and so on.

Hundreds of books and thousands of articles have been written about
UML, and no other notation is as well described.  That's the good
news; the bad news is that in all the years I've been programming,
I've only ever met one person who drew UML diagrams of his own free
will on a regular basis.  I've known a handful of other people who
occasionally sketched class diagrams as part of a larger description
of a design, and that's pretty much it.  When I contrast that with
blueprints in architecture, or flow diagrams in chemical engineering,
the only conclusion I can reach is that software developers don't
actually find UML very helpful.

I think there are several reasons for this, including its lack of a
well-defined semantics and the fact that UML diagrams can't be diffed
and merged by version control systems (\secref{s:tooling-versioning}).
However, since it's all that we have, in most books, likely to be on
the final exam, and might come up in an interview, it's still worth
mastering the basics.

%----------------------------------------------------------------------
\seclbl{Getting Started}{s:design-start}
%----------------------------------------------------------------------

What if you're starting with a blank sheet of paper (or an empty
whiteboard)?  How do you describe something that doesn't exist yet?
The best way to start is to write your elevator pitch
(\secref{s:basics-pitch}).  Next, write one or two paragraph-long
stories describing how the application, feature, or library would be
used.  Be as concrete as possible: instead of saying, ``Allows the
user to find overlaps between their calendar and their friends'
calendars,'' say, ``The user selects one or more of her friends'
calendars (and optionally her own), and the system displays a page
showing events that two or more people are going to, color coded to
show how popular they are.''

Once you have those narratives, go through and highlight the key
``things'' and ``relationships'' you've just described.  In the
example above, you would highlight ``user'', ``friend'', ``calendar'',
``event'', ``page'', and so on.  As soon as you try to draw a
blob-and-arrow diagram showing how these are related to one another,
you'll have to start making design decisions: for example, is
``friend'' an entity, or a relationship between two entities (i.e., is
it a blob or an arrow)?

If, during this process, you hear yourself say, ``We'll use a linked
list to{\ldots}'' then step back and catch your breath.  Details like
that do need to be worked out at some point, but:

\begin{itemize}

  \item you're probably worrying about that as a way to \emph{not}
  think about the bigger design questions (which are scarier for
  beginners);

  \item you probably don't know enough yet about your design to make
  the right decision; and

  \item you're probably a good enough coder by now that you can worry
  about that when the time comes to actually write the code.
  Remember, not everything actually needs to be designed{\ldots}

\end{itemize}

Once you have a diagram---any kind of diagram---you should start
iterating around it.  Pick one open problem (such as ``how will users
control who can see their calendars?''), think of a way to solve it
(``they can mark them as 'public', or invite specific people to view
them''), figure out how to implement your solution, then revisit any
previous decisions that your most recent decisions affect.  Design is
a very cyclic process: every time you add or change one thing, no
matter how small, you may need to go back and re-design other things.

There are two traps here for the inexperienced.  The first is
\defterm{analysis paralysis}, in which you find yourself revisiting
issues over and over again without ever making any decisions that
stick.  The second is the \defterm{already invented here} syndrome, in
which someone (possibly you) says, ``Look, we've already made a
decision about that, let's not reopen the debate.''  Either can sink a
project; together, they show why it's so hard to teach design, since
what I'm basically saying is, ``Argue enough, but not too much.''
Helpful, isn't it?

%----------------------------------------------------------------------
\seclbl{Design for Testability}{s:design-testability}
%----------------------------------------------------------------------

When most developers hear the word ``design'', they think about either
the application's structure or its user interface.  If you don't think
about how you're going to test your application while you're designing
it, though, the odds are very good that you'll build something that
can't (or cannot easily) be tested.  Conversely, if you
\defterm{design for test}, it'll be a lot easier to check whether your
finished application actually does what it's supposed to.

For example, let's consider a typical three-tier web site that uses
the Model-View-Controller (MVC) design pattern
(\figref{f:design-mvc}).  The model, which is stored in a relational
database, is the data that the application manipulates, such as
purchase orders and game states.  The controller layer encapsulates
the application's business rules: who's allowed to cancel games while
they're in progress, how much interest to add on out-of-province
orders, and so on.  Finally, the view layer translates the
application's state into HTML for display to the user.

\begin{figure}
  \FIXME{Original Application Configuration}
  \caplbl{Original Application Configuration}{f:design-mvc}
\end{figure}

This architecture presents (at least) three challenges from the point
of view of testing:

\begin{enumerate}

  \item Unit testing libraries like \url{JUnit} (and its clones in
  other languages) aren't built to handle this: as the word
  ``library'' implies, they're made up of code that's meant to be
  called \emph{within} a process.  Despite the ubiquity of
  multi-process applications, most debuggers and testing libraries
  cannot track ``calls'' \emph{between} processes.

  \item Configuring a test environment is a pain: you have to set up a
  database server, clear the browser's cache, make sure the right
  clauses are in your Apache configuration file, and so on.

  \item Running tests is slow. In order to ensure that tests are
  independent, you have to create an entirely new fixture for each
  test.  This means reinitializing the database, restarting the web
  server, and so on, which can take several seconds \emph{per
  test}. That translates into an hour or more for a thousand tests,
  which is pretty much a guarantee that developers won't run them
  routinely while they're coding, and might not even run them before
  checking changes in.

\end{enumerate}

The first step in fixing this is to get rid of the browser and web
server. One way to do this is to replace the browser with a script
that generates HTTP requests as multi-line strings and passes them to
a ``fake CGI'' library via a normal function call
(\figref{f:design-back-end}).  After invoking our actual program, the
fake CGI library passes the text of an HTTP response back to our
script, which then checks that the right values are present (about
which more in a moment). The ``fake CGI'' library's job is to emulate
the environment the web app under test would see if it was being
invoked as a CGI by Apache: environment variables are set, standard
input and output are replaced by string I/O objects, and so on, so
that the web app has no (easy) way of knowing that it's being invoked
via function call, rather than being forked.

\begin{figure}
  \FIXME{Image of isolating the back end.}
  \caplbl{Isolating the Back End}{f:design-back-end}
\end{figure}

Why go through this rigmarole? Why not just have a top-level function
in the web app that takes a URL, a dictionary full of header keys and
values, and a string containing the POST data, and check the HTML page
it generates? The answer is that structuring our tests in this way
allows us to run them both in this test harness, and against a real
system. By replacing the fake CGI adapter with code that sends the
HTTP request through a socket connected to an actual web server, and
reads that server's response, we can check that our application still
does what it's supposed to when it's actually deployed. The tests will
run much more slowly, but that's OK: if we've done our job properly,
we'll have caught most of the problems in our faked environment, where
debugging is much easier to do.

Now, how to check the result of the test? We're expecting HTML, which
is just text, so why not store the HTML page we want in the test and
do a string comparison? The problem with that literal approach is that
every time we make any change at all to the format of the HTML, we
have to rewrite every test that produces that page.  Even something as
simple as introducing white space, or changing the order of attributes
within a tag, will break string comparison.

A better strategy is to add unique IDs to significant elements in the
HTML page, and only check the contents of those elements. For example,
if we're testing login, then somewhere on the page there ought to be
an element like this:

\begin{alltt}
<div id="currentuser">Logged in as <strong>gvwilson</strong>
(<a href="http://www.drproject.org/logout">logout</a>
|
<a href="http://www.drproject.org/preferences">preferences</a>)
</div>
\end{alltt}

We can find that pretty easily with an \defterm{XPath} query, or by
crawling the DOM tree produced by parsing the HTML
ourselves\footnote{Assuming we're generating well-formed HTML, which
we should be.}.  We can then move the \code{div} around without
breaking any of our tests; if we were a little more polite about
formatting its internals (i.e., if we used something symbolic to
highlight the user name, and trusted CSS to do the formatting), we'd
be in even better shape.

We've still only addressed half of our overall problem, though: our
web application is still talking to a database, and reinitializing it
each time a test runs is sloooooooow.

We can solve this by moving the database into memory
(\figref{f:design-replacing-db}).  Most applications rely on an
external database server, which is just a long-lived process that
manages data on disk. An increasingly-popular alternative is the
\emph{embedded} database, in which the database manipulation code runs
inside the user's application as a normal library.  \url{Berkeley DB}
(now owned by \url{Oracle}) and \url{SQLite} (still open source) are
probably the best known of these; their advocates claim they are
simpler to build and faster to run, although there are lots of
advantages to using servers as well.

\begin{figure}
  \FIXME{Figure of replacing the database.}
  \caplbl{Replacing the Database.}{f:design-replacing-db}
\end{figure}

The advantage of embedded databases from a testing point of view is
that they can be told to store data in memory, rather than on
disk. This would be a silly thing to do in a production environment
(after all, the whole point of a database is that it persists), but in
a testing environment, it can speed things up by a factor of a
thousand or more, since the hard drive never has to come into
play. The cost of doing this is that you have to either commit to
using one database in both environments, or avoid using the
``improvements'' that different databases have added to SQL.

Once these changes have been made, the application zips through its
tests quickly enough that developers actually will run the test suite
before checking in changes to the code. The downside is the loss of
\defterm{fidelity}: the system we're testing is a close cousin to what
we're deploying, but not exactly the same. However, this is a good
economic tradeoff: we may miss a few bugs because our fake CGI layer
doesn't translate HTTP requests exactly the same way Apache and
Python's libraries do, but we catch (and prevent) a lot more by making
testing cheap.

This example just scratches the surface of designing for testability.
If you want to go further, \cite{b:meszaros-xunit} includes some good
discussion of how to make things more testable, and in 2007, Michael
Bolton posted a fairly complete list of things developers can do to
the Agile Testing list:

\begin{enumerate}

  \item scriptable interfaces to the product, so that we can drive it
  more easily with automation

  \item logging of activities within the program

  \item monitoring of the internals of the application via another
  window or output over the network

  \item simpler setup of the application

  \item the ability to change settings or configuration of the
  application on the fly

  \item clearer error/exception messages, including unique identifiers
  for specific points in the code, or \emph{which} damn file was not
  found

  \item availability of modules separately for earlier
  integration-level testing

  \item information about how the system is intended to work (ideally
  in the form of conversation or ``live oracles'' when that's the most
  efficient mode of knowledge transfer)

  \item information about what has already been tested (so we don't
  repeat someone else's efforts)

  \item access to source code for those of us who can read and
  interpret it

  \item improved readability of the code (thanks to pairing and
  refactoring)

  \item overall simplicity and modularity of the application

  \item access to existing ad hoc (in the sense of ``purpose-built'')
  test tools, and help in creating them where needed

  \item proximity of testers to developers and other members of the
  project community

\end{enumerate}

\noindent Adam Goucher added two more:

\begin{enumerate}
\setcounter{enumi}{14}

  \item a ``stub mode'' where you can test a module without needing
  another module reading/working

  \item information about what has changed since the last code
  delivery in order to better target testing

\end{enumerate}

Of these, numbers 2, 6, 7, 9, and 15 are the most important for
students' projects; most of the others only really come into play when
you're building something very large, or have a team that's so big
that it has to be broken down into functional groups.  That said,
they're all still good ideas at every level of development.

%----------------------------------------------------------------------
\seclbl{Keeping Track}{s:design-numbering}
%----------------------------------------------------------------------

If your project is run like most, you're going to submit your work
several times over the course of the term.  That means it's important
for you to keep track of exactly what version you're working on at any
time, where it came from, and where it's going.

The usual way to do this is with \defterm{version numbers}.  If you
see a number like ``6.2.3.1407'' attached to a piece of software, it
generally means:

\begin{itemize}

  \item major version 6

  \item minor version 2

  \item patch 3

  \item build 1407

\end{itemize}

The major version number is only incremented when significant changes
are made.  In practice, ``significant'' means ``changes that make it
impossible for older versions to read the new version's data or
configuration files''.  In practice, major version numbers are often
under the control of the marketing department---if a competitor
releases a new major version, we'd pretty much have to as well.

Minor version numbers are what most people think of as releases.  If
you've added a few new features, changed part of the GUI, etc., you
increment the minor version number so that your customers can talk
intelligently about which version they have.

Patches are things that don't have their own installers.  If, for
example, you need to change one HTML form, or one DLL, you will often
just mail that out to customers, along with instructions about where
to put it, rather than creating a new installer.  You should still
give it a number, though, and make an entry in your release
log\footnote{A ``release log'' is a file (often a spreadsheet) that
records exactly what was shipped to whom, when.}.

The build number is incremented every time you create a new version of
the product for QA to test.  Build numbers are never reset, i.e. you
don't go from 5.2.2.1001 to 6.0.0.0, but from 5.2.2.1001 to
6.0.0.1002, and so on.  Build numbers are what developers care about:
they're often only matched up with version numbers after the fact
(i.e.  you create build \#1017, QA says, ``It looks good,'' so you
say, ``All right, this'll be 6.1.0,'' and voila, you have 6.1.0.1017.)

Finally, groups will sometimes identify pre-releases as ``beta 1'',
``beta 2'', and so on, as in ``6.2 beta 2''.  Again, this label is
usually attached to a particular build after the fact---you wait until
QA (or whoever) says that build \#1017 is good enough to send out to
customers, then tag it in version control.

A four-part numbering scheme is more than you need for an
undergraduate course.  You can probably get away with just two
numbers: one to identify the assignment the software was submitted
for, and another to identify the files that went into that
``release''.

Why include this in a discussion of design?  Well, it turns out that
\url{Subversion} and other version control systems will include
version numbers automatically in every file
(\secref{s:design-numbering}).  If you put the string
\code{\$Revision:\$} in a file, and set the \code{svn:keywords}
property on that file, then every time you commit changes, Subversion
will replace everything between the colon and the trailing dollar sign
with the revision number of the file.  \url{Subversion} will do the
same thing for \code{Author}, \code{Date}, and several other keywords.

For example, if the file contains:

\begin{alltt}
# cleanup.py : Clean up files left behind by the CAD software.
# $Revision: 81$
# $Author: aturing$

import sys, os
{\ldots}
\end{alltt}

\noindent and Grace Hopper commits changes that update the repository
to version 99, the file will be changed to:

\begin{alltt}
# cleanup.py : Clean up files left behind by the CAD software.
# $Revision: \textbf{99}$
# $Author: \textbf{ghopper}$

import sys, os
{\ldots}
\end{alltt}

Now, take a look at this snippet of Java:

\begin{alltt}
public class Student extends Person {
    public static final String Revision = "\$Revision: 82";
    {\ldots}
    public String getRevision() {
        return Revision;
    }
}
\end{alltt}

Whenever a change to this file is committed to version control, the
class's version number is automatically updated.  Inside a running
program, you can then ask any \code{Student} object, ``What version of
this class are you?''  (As an exercise, write a method that strips the
front and back off the revision string, and returns the revision
number as an integer.)  If you are working with systems that load
classes dynamically, like the \url{Tomcat} servlet container or the
\url{Eclipse} IDE, knowing exactly which version of your code has
actually been loaded can save you many, many hours.

%----------------------------------------------------------------------
\seclbl{Logging}{s:design-logging}
%----------------------------------------------------------------------

Something else you can design into your system to make your life
easier later on is \defterm{logging}.  This is the grown-up way to
debug with print statements.  Instead of writing:

\begin{alltt}
def extrapolate(basis, case):
    print "entering extrapolate..."
    trials = count_basis_width(basis)
    if not trials:
        print "...no trials!"
        raise InvalidDataException("no trials")
    print "...running", len(trials), "trials"
    result = run_trial(trials[0])
    for t in range(1, len(trials)):
        result = max(result, run_trial(trials[i]))
    print "...exiting extrapolate with", result
\end{alltt}

you use your language's logging library\footnote{Every modern language
has a logging facility.  If you're using Java, for example, the de
facto standard is Apache's \url{log4j}.}, like this:

\begin{alltt}
\textbf{from logging import error, debug}
def extrapolate(basis, case):
    \textbf{debug("entering extrapolate...")}
    trials = count_basis_width(basis)
    if not trials:
        \textbf{warning("...no trials!")}
        raise InvalidDataException("no trials")
    \textbf{debug("...running \%d trials" \% len(trials))}
    result = run_trial(trials[0])
    for t in range(1, len(trials)):
        result = max(result, run_trial(trials[i]))
    \textbf{debug("...exiting extrapolate with \%d" \% result)}
\end{alltt}

At first glance, this is just more verbose.  The benefit, though, is
that your messages are now divided into two classes.  If you want to
get all the messages, you put:

\begin{alltt}
logging.basicConfig(level=logging.DEBUG)
\end{alltt}

somewhere near the start of your program.  \code{DEBUG} identifies the
least important messages in your program---the ones you probably only
want to see when you're trying to figure out what's gone wrong.  In
order, the more important levels (in Python's logging
framework---other libraries define these slightly differently) are
\code{INFO}, \code{WARNING}, \code{ERROR}, and \code{CRITICAL}.  If
you only want messages at the \code{WARNING} level and above, you
change the configuration to:

\begin{alltt}
logging.basicConfig(level=logging.WARNING)
\end{alltt}

so that \code{DEBUG} and \code{INFO} messages aren't printed.

A logging library allows you to control how much your program tells
you about its execution by making one change, in one place.  It also
means that you can leave these messages in your code, even when you
release it.  No more commenting out \code{print} statements, only to
add them back in later.  (And no more inappropriately-worded messages
that \emph{weren't} commented out popping up in the middle of demos.)

But wait, there's more.  Logging libraries also let you control where
your messages are sent.  By default, they go to the screen, but you
can send them to a file instead simply by changing the configuration:

\begin{alltt}
logging.basicConfig(level=logging.ERROR,
                    filename="/tmp/mylog.txt",
                    filemode="append")
\end{alltt}

This is handy if it takes your program a while to get to the point
where the error occurs.  It's also handy if you don't know whether
your program contains an error or not: if you leave logging turned on
every time you run it, then whenever it does something unexpected
(like crashing), you will have at least some idea of what it was doing
beforehand.

Most logging libraries also support \defterm{rotating files}, i.e.,
they will write to \code{log.1} on the first day, \code{log.2} on the
second day, and so on until they reach (for example) \code{log.7},
then wrap around and overwrite \code{log.1}.  Web servers and other
long-lived programs are usually set up to do this so that they don't
fill up the disk with log information.

Finally, logging libraries can send output to mail servers, cell
phones, web servers, and Lava Lamps to notify system administrators
when something \code{CRITICAL} happens.  You can also define message
categories, like ``database operations'' or ``login and logout'', and
then tell the logging library to only save specific kinds of messages.
It's all straightforward to set up, and once it's in place, it gives
you a lot more insight into what your program is actually doing.

%======================================================================
\chaplbl{Wrapping Up}{s:wrapup}
%======================================================================

In most courses, once you've handed in an assignment you're done with
it.  Course projects are different: they often roll forward from one
term to the next, so the end of one team's involvement isn't
necessarily the end of the project, and they are meant to simulate
real life, where delivery of a particular version is just another step
in the product lifecycle.  Here, then, are some of the things you
might be asked to do at the end of your project.

%----------------------------------------------------------------------
\seclbl{The Project}{s:wrapup-project}
%----------------------------------------------------------------------

As I've already said several times, software development teams in
industry care almost as much about handing their projects off cleanly
as they do about what's actually in any particular release (in part
because they themselves are the people most likely to be affected).
This usually isn't part of undergraduate project courses, but it
should be; if your instructor is enlightened enough to include this in
her grading scheme, here are some things she might look for:

\begin{enumerate}

  \item An attractive home page, with a short vision statement
  (\secref{s:basics-pitch}) and a few paragraphs or bullet lists to
  help newcomers orient themselves.

  \item An FAQ.

  \item An architectural overview, including block diagrams of the
  major components and a walkthrough of the processing cycle.

  \item An installation guide.

  \item An up-to-date set of tickets.  If the work has been done, the
  ticket should be closed; if it hasn't, the ticket should describe
  the state of the bug (or enhancement, or question) fully and
  accurately.

\end{enumerate}

%----------------------------------------------------------------------
\seclbl{Bugs}{s:wrapup-bugs}
%----------------------------------------------------------------------

It's OK to have bugs in your code when you finish your project.  After
all, almost all products have bugs in them when they ship.  This isn't
because developers are lazy or careless; instead, it's a matter of
economics.  More than half of first attempts to fix a problem contain
bugs\comment{Need a citation for this.}.  That means that if you're
near the end of the development cycle, ``fixing'' a minor bug can
actually \emph{increase} the chances of the program crashing or
destroying users' data.  It's safer to document it (and a workaround,
if any exists).

This is another way in which student projects differ from their
industrial counterparts.  I have yet to see an instructor give
students marks for cataloging the bugs still in their code at the end
of term, probably because it would be so much work to mark.  Instead,
grades are often allocated based on a set of automated pass/fail
acceptance tests, and a subjective evaluation of the code's quality
(which usually means its conformance to basic rules of indentation,
commenting, and variable naming).

%----------------------------------------------------------------------
\seclbl{The Final Report}{s:wrapup-report}
%----------------------------------------------------------------------

The other thing student projects usually have to deliver is some kind
of final report.  Most students short-change this part of the course,
in part because it comes at the end, but also because they think, ``I
want to write code, not a novel.''  But here's Karl Fogel, one of the
architects of \url{Subversion} and author of \emph{Producing Open
Source Software}, on writing \cite{b:fogel-producing-open-source}:

\begin{quotation}

  The ability to write clearly is perhaps the most important skill one
  can have in an open source environment.  In the long run it matters
  more than programming talent.  A great programmer with lousy
  communication skills can only get one thing done at a time, and even
  then may have trouble convincing others to pay attention.  But a
  lousy programmer with good communication skills can coordinate and
  persuade many people to do many different things, and thereby have a
  significant effect on a project's direction and momentum.

\end{quotation}

End-of-project reports can range from half a dozen to fifty pages,
depending on the course's structure and the instructor's whims.
Regardless of their size, they will usually include the following:

\begin{itemize}

  \item A \emph{title page}, \emph{abstract}\footnote{For some reason,
  computer scientists often write abstracts that are like movie
  trailers or elevator pitches, rather than proper summaries. ``We
  will contrast frobnication with jamframification'' doesn't help
  people who have a hundred articles to skim; ``We show that
  frobnication is 28\% more likely to spleedle than jamframification
  under heavy load'' is a lot more useful.}, and \emph{table of
  contents}.  The first identifies the document; the second summarizes
  it in three or four sentences, so that busy people can decide
  whether they ought to read the whole thing; and the third helps
  people navigate.

  \item An \emph{introduction} which sets the stage for the rest of
  the document.  This explains what problem the team set out to solve,
  and summarizes any background knowledge needed to understand the
  team's solution.  It shouldn't state the obvious: there's no need to
  tell readers what the Internet is, or how a parser works.  Instead,
  it should cover whatever general knowledge the \emph{next} team will
  need in order to continue the project.

  \item A \emph{description of what was done}.  This should \emph{not}
  simply rehash the A\&E (\secref{s:process-plansched}), although
  that's a good place to start. Instead, it should describe the
  system's architecture, any features of its data formats, class
  structure, or UI that won't immediately make sense to a
  knowledgeable observer, and so on.  As with the introduction, the
  target audience is the next team to work on the project.

  \item A \emph{summary of the current state of the project},
  including high-level criticism (``The persistence layer works fine,
  but in retrospect, our concurrency control mechanism was a bad
  choice'') and pointers to specifics (``Ticket 213 should be
  addressed before any further work is done on user preferences'').

  \item An \emph{evaluation} of the project.  What did the team learn
  about teamwork?  What went well?  What should they never do again?
  Motherhood-and-apple-pie statements about the importance of version
  control don't belong here (or anywhere else).  Instead, the team
  should conduct a proper post mortem (\secref{s:wrapup-postmortem})
  and present as honest a summary of its findings as possible.

  \item \emph{References}, including books, papers, and links that the
  team found helpful.

\end{itemize}

As you can see, this report is neither a user's guide nor maintenance
documentation.  Instead, it is like the end-of-contract reports I had
to prepare when I was a consultant.  What had I done to earn my
customers' money?  What should the next person (who might not be me)
do?  What could I tell them that would save them time?  Internal
documentation (like Javadoc) doesn't help with these questions, and
anyway, the team should be producing that as they go along, not all in
a rush at the end of term.

So much for what the final report should include; how should you
actually go about writing it?  It will probably include:

\begin{itemize}

  \item paragraphs of text;

  \item equations;

  \item source code;

  \item vector graphics (such as graphs and line drawings); and

  \item raster graphics (such as screen shots).

\end{itemize}

Lots of tools exist that will handle these, but they all have their
flaws.  You can create your report as a set of wiki pages, but most
wikis don't handle conflicts between concurrent authors, and wikis
don't do equations or graphics any better than plain old HTML.

On the other end of the spectrum are WYSIWYG editors like
\url{Microsoft Word} and \url{OpenOffice}.  Unfortunately, these get
in the way at least as much as they help:

\begin{enumerate}

  \item They store documents in non-text formats that version control
  systems can't diff or merge (\secref{s:tooling-versioning}).

  \item It's hard to write scripts to process documents, so inclusions
  (such as code fragments) have to be done manually.

  \item Neither one handles equations very well (although both are
  getting better).

  \item It's very easy to format things using low-level primitives
  (``make this italic'') rather than logical styles (``making this a
  book title''), which makes it difficult to keep the document
  consistent over time.

\end{enumerate}

For these reasons, most teams format their reports as a set of HTML
pages under version control.  That solves the problem of multiple
authors (HTML is a text format, so diff and merge will work), and if
you know a little CSS, you can make it look as pretty as you want.
Diagrams and screenshots work well, but equations are problematic:
\url{MathML} (the mathematical markup language) is complicated to
write and poorly supported, so many people still resort to embedding
pictures of equations in web pages.

If you're really keen, you can use an XML markup format like
\url{DocBook}, which provides a set of semantically-meaningful tags
like \code{<author>} and \code{<citation>}.  Various tools can then
compile the XML into HTML, PDF, or other formats.  I've tried this,
but have never been satisfied: it takes a lot of typing (or mousing)
to add all those tags, which makes \url{DocBook} feel like overkill
for a simple end-of-term report.

Then there's \url{LaTeX}, a markup language that's much more
sophisticated than HTML, and has literally thousands of add-on
packages for equations, code formatting, and just about everything
else you could want.  Like HTML, \url{LaTeX} is a text format, so it
plays nicely with version control.  However, its power comes at a
steep price: \url{LaTeX} is as hard to master as a programming
language.  It also has a frustratingly slow formatting cycle, since
documents have to be compiled into PDF or another viewable format
before you can see the effects of your changes (although WYGIWYG tools
like \url{LyX} are making great strides).

%----------------------------------------------------------------------
\FIXME{\seclbl{Presentations and Demos}{s:wrapup-preset}}
%----------------------------------------------------------------------

%----------------------------------------------------------------------
\seclbl{The Post Mortem}{s:wrapup-postmortem}
%----------------------------------------------------------------------

The most valuable part of your project isn't the software you write,
or the grade you're given.  It's the project's \defterm{post mortem}.
Literally, this is an examination of a deceased person; in a software
project, it's a look back at what went right, and what went wrong.

The aim of a post mortem is to help the team and its members do better
next time by giving everyone a chance to reflect on what they've just
accomplished.  It is \emph{not} to point the finger of shame at
individuals, although if that has to happen, the post mortem is the
best place for it.

Post mortems are pretty easy to run---just add the following to the
rules for running a meeting (\secref{s:important-meetings}):

\begin{enumerate}

  \item \emph{Get a moderator who wasn't part of the project} and
  doesn't have a stake in it.  Otherwise, the meeting will either go
  in circles, or focus on only a subset of important topics.  In the
  case of student projects, this moderator might be the course
  instructor, or (if the course is too large, or the instructor is
  lazy) a TA.

  \item \emph{Set aside an hour, and only an hour.} In my experience,
  nothing useful is said in the first ten minutes of anyone's first
  post mortem, since people are naturally a bit shy about praising or
  damning their own work.  Equally, nothing useful is said after the
  first hour: if you're still talking, it's probably because one or
  two people have a \emph{lot} they want to get off their chests.

  \item \emph{Require attendance.} Everyone who was part of the
  project ought to be in the room for the post mortem.  This is more
  important than you might think: the people who have the most to
  learn from the post mortem are often least likely to show up if the
  meeting is optional.

  \item \emph{Make two lists.} When I'm moderating, I put the headings
  ``Good'' and ``Bad'' on the board, then do a lap around the room and
  ask every person to give me one item (that hasn't already been
  mentioned) for each list.

  \item \emph{Comment on actions, rather than individuals.} By the
  time the project is done, some people simply won't be able to stand
  one another.  Don't let this sidetrack the meeting: if someone has a
  specific complaint about another member of the team, require him to
  criticize a particular event or decision.  ``He had a bad attitude''
  does \emph{not} help anyone improve their game.

\end{enumerate}

Once everyone's thoughts are out in the open, organize them somehow so
that you can make specific recommendations about what to do next time.
This list is one of the two major goals of the post mortem (the other
being to give people a chance to be heard).  For example, here are the
recommendations that came out of a post mortem I did with students in
2006:

\begin{enumerate}

  \item Do a better job of tracking actual progress, rather than
  reported progress.  Maybe require a one-minute demo every time a
  feature is supposedly completed?

  \item Teams should find one block of 2-3 hours per week when they
  can work side by side: IM meetings and email resulted in a lot of
  dropped balls.

  \item Having someone who worked on the project in the previous term
  come in to get the new team up to speed made a huge difference.

  \item Team members should read each other's code, at least during
  the early stages of the project, to make sure everyone is actually
  following the coding guidelines.

  \item A large number of small commits is better than a small number
  of massive commits.

  \item Ticketing system was too complicated for students' needs:
  really just want a shared online to-do list.

  \item Teams should have to report test coverage at every progress
  meeting to make sure that a lot of untested code doesn't pile up
  during the term.

\end{enumerate}

%======================================================================
\chaplbl{Final Words}{s:final}
%======================================================================

So, let's see how you're doing.  Give yourself one mark for each
``yes'', 0 for a ``no'', and -1 for ``I don't know'' or ``I don't
understand the question''.

\begin{enumerate}

  \item Does your project have a vision statement, and does everyone
  know what it is?

  \item Do you have a up-to-date spec\footnote{The spec can be as
  simple as specially-flagged tickets in the bug database.}, and does
  everyone know what and where it is?

  \item Is every project resource saved in version control?

  \item Can you rebuild your project with a single command?

  \item Do you write tests before writing code?

  \item Do you always run your tests before checking changes into
  version control?

  \item Do you have a bug database?

  \item Do you use assertions and other defensive programming
  techniques?

  \item Do you use a symbolic debugger to track problems down?

  \item Do you embed your documentation in your code?

  \item Is there a searchable archive of discussions about the
  project?

  \item Do you use a style checker to maintain code quality?

  \item Do you have an up-to-date schedule?

  \item Do you do development in a distraction-free environment (yes,
  that means ``with instant messaging and email turned off'')?

  \item Do you work steadily, without all-nighters or last-minute
  panic sessions?

\end{enumerate}

How did you do?

\begin{itemize}

  \item Negative: please re-read this document, make some changes, and
  then come back and take this quiz again.

  \item 0-5: your project will probably fail to deliver anything
  useful.

  \item 6-10: most mature development teams are in this range, and can
  bootstrap other improvements they need on their own.

  \item 11-15: if you're looking for a job, please let me know.

\end{itemize}

\seclbl{Why I Teach}{s:final-why-teach}

When I was your age, I thought universities existed to teach people
how to learn.  Later, when I was in grad school, I thought
universities were about doing research and creating new knowledge. Now
that I'm in my forties, though, I've realized that what we're really
doing here is teaching you how to take over the world---because
whether you like it or not, you're going to have to one day.

My parents are in their seventies, and retired.  Their generation
doesn't run the world any more; instead, it's people my age, or a bit
older, who pass laws, decide whether interest rates will go up or
down, and make life-and-death decisions in hospitals.  As scary as it
seems, \emph{we} are now the grownups.

Twenty years from now, though, we'll be heading for retirement, and
\emph{you} will be in charge, because there won't be anyone else to do
it.  That may sound like a long time when you're nineteen, but let me
tell you, you take three breaths, and it's gone.  That's why we give
you problems whose answers can't be cribbed from last year's notes.
That's why we put you in situations where you have to figure out what
needs to be done right now, what can be left for later, and what you
can simply ignore.  It's because if you don't start learning how to do
these things now, you won't be ready to do them on your own when you
have to.

Stirring stuff, isn't it? But it's not the whole answer.  I don't just
want my students to make the world a better place so that I can retire
in comfort.  I want them to make it a better place for everyone,
because I think that's the great adventure of our times. Forget about
landing on the moon and unraveling the genetic code: when future
historians write about our era, what they'll focus on is that for the
first time in history, our species started taking the Golden Rule
seriously.

Just think: a hundred and fifty years ago, most societies still
practiced slavery.  A hundred years ago, when my grandmother was a
young girl, she wasn't legally a person in Canada.  Fifty years ago,
most of the world's people suffered under totalitarian rule; in the
year I was born, African-Americans couldn't vote in Southern states,
and judges could---and did---order electroshock therapy to ``cure''
homosexuals. Yes, there's still a lot wrong with the world, but look
at how many more choices you have than your grandparents did.  Look at
how many more things you can know, and be, and enjoy.  And most
importantly, look at how many other people can too.

This didn't happen by chance.  It happened because millions of us made
millions of little decisions, the sum of which was a better world.
For the most part, we don't think of these day-to-day decisions as
being political, but they are.  Every time we buy one brand of running
shoe instead of another, every time we choose to take this class
instead of that one, every time we \emph{don't} give the homeless guy
on the corner fifty cents, every time we decide to shout an anatomical
insult instead of a racial one at a cabbie who shouldn't be allowed to
drive a shopping cart, we're putting our weight behind one vision of
what the world should be rather than another.  We don't think about
this bigger picture most of the time---we'd be paralyzed if we did.
But the last century and a half shows that once enough people make
``doing the right thing'' a habit, the big picture more or less takes
care of itself.

In his 1947 essay ``Why I Write'' \cite{b:orwell-why-i-write}, George
Orwell said:

\begin{quotation}

  In a peaceful age I might have written ornate or merely descriptive
  books, and might have remained almost unaware of my political
  loyalties.  As it is I have been forced into becoming a sort of
  pamphleteer{\ldots} Every line of serious work that I have written
  since 1936 has been written, directly or indirectly, against
  totalitarianism{\ldots} It seems to me nonsense, in a period like
  our own, to think that one can avoid writing of such subjects.
  Everyone writes of them in one guise or another. It is simply a
  question of which side one takes and what approach one follows.

\end{quotation}

Replace ``writing'' with ``teaching'', and you'll have the real reason
I'm taking on twenty students next term.  Every line of code you write
changes the world in some small way.  Every deadline you meet, every
security hole you don't plug, every user need you satisfy, every
disability you don't accommodate---each one makes tomorrow different
from today.

I teach because I want you to be aware of that.  I want you to be
conscious of the fact that you're shaping the future we're all going
to spend the rest of our lives in.  I want you to do things right, and
to believe that doing things right is important, because the world
doesn't get better by chance, or on its own.  The world gets better
because people like you make it better: penny by penny, brick by
brick, vote by vote, and one line of code at a time.

\bibliographystyle{plain}
\bibliography{guide}

\appendix

\chaplbl{Performance Evaluation}{s:evaluation}

\emph{The material reproduced below is taken from the guidelines for
annual performance reviews used at a well-known (and rather cool)
software development company.  It's an accurate depiction of what
companies really care about, and look for, in software developers.}

The purpose of this document is to define best practices for all
software developers in order to facilitate their professional
development.

\begin{enumerate}

\item \textbf{Software engineering} (technical design; architecture;
coding; debugging; testing; performance optimization; release;
maintenance)

  \begin{enumerate}

  \item Records technical requirements, architectural decisions, and
  other relevant information (does ``just enough'' design to answer
  all stakeholders' questions; analyzes and reviews peers' designs;
  takes resource usage into account during design; no ``hidden
  features''; takes security needs into account)

  \item Plans for evolution and maintenance (avoids excessive
  dependencies; allows for future maintenance; accounts for deployment
  issues, particularly upgrades)

  \item Uses configuration management system effectively (all
  project-related material is versioned; never breaks the build; all
  changes are connected to tickets in an auditable way)

  \item Uses ticketing system effectively (all questions, tasks, and
  issues are ticketed; all work is associated with ticketed items;
  tickets are kept up to date to serve as a basis for auditable status
  reports; avoids creating redundant/duplicate tickets)

  \item Manages schedule (provides time estimates on work items, and
  updates completion estimates as work progresses; proactively reports
  delays and other scheduling-related issues to affected stakeholders;
  proactively searches for ways to reduce the project's critical path)

  \item Conforms to company coding guidelines (code always passes
  format checks; documentation of all inter-module and
  externally-visible APIs is always up to date on main branch;
  developer-oriented documentation phrased in terms of recognized
  design patterns where relevant)

  \end{enumerate}

\item \textbf{Communication} (verbal communication; written reports;
presentations; email; wikis; blogs; active listening skills; feedback
and critiques)

  \begin{enumerate}

  \item Effectively communicates with peers and stakeholders in a
  regular and timely fashion (collaborates regularly with colleagues
  from other divisions; updates manager and team regularly and
  accurately on status)

  \item Asks for assistance when needed (seeks answers before asking
  for assistance, but escalates problems when blocked; when asking for
  help, clearly and accurately explains what has been tried, and why
  it didn't work)

  \item Provides helpful feedback to peers (takes active role in
  design meetings, code reviews, etc.; provides specific examples and
  suggestions for improvement when critiquing colleagues' work)

  \item Improves efficiency (automates repetitive tasks through
  scripts, macros, etc.; proactively does in-phase work that will
  reduce time and overhead in subsequent work phases)

  \item Proactively expands network of personal contacts (participates
  in relevant internal discussion groups; takes initiative to
  establish contacts with colleagues in upstream and downstream
  groups)

  \end{enumerate}

\item \textbf{Domain Expertise} (sharing knowledge; innovating;
continued development of personal skills)

  \begin{enumerate}

  \item Proactively shares knowledge with peers (mentoring; blogging
  tips and tricks; updating project wiki; provides training)

  \item Looks for opportunities to innovate (willing to import
  relevant knowledge from other groups/projects/companies; stays
  current with relevant literature; proposes and pursues patents)

  \item Actively improves expertise (attends training courses; seeks
  to understand goals and techniques of upstream and downstream
  groups; proactively adopts good practices used by peers)

  \end{enumerate}

\item \textbf{Leadership} (communicating vision to peers and
subordinates; fostering a supportive environment; taking a ``big
picture'' view of product development)

  \begin{enumerate}

  \item Takes part in team-building activities (interviews potential
  hires; helps orient new hires; communicates consistently with
  subordinates regarding their status and performance; takes part in
  out-of-hours social events)

  \item Solves problems proactively and methodically (identifies
  risks; prioritizes outstanding issues; looks for low-cost/low-risk
  ways to solve or avoid problems; prefers ``win-win'' solutions to
  ``zero-sum'' solutions)

  \item Uses metrics for process improvement (measures and records
  development times, memory/CPU loads, etc.; translates this data into
  recommendations for process and/or product improvement)

  \item Contributes to project planning (participates in post mortems;
  evaluates feasibility of design and feature proposals; explains
  technical issues/opportunities to upstream and downstream
  colleagues)

  \end{enumerate}

\end{enumerate}

%======================================================================
\chaplbl{Links}{s:links}
%======================================================================

\begin{itemize}

  \item Amaya: http://www.w3.org/Amaya

  \item Ant: http://ant.apache.org

  \item Apache: http://httpd.apache.org

  \item Bugzilla: http://www.bugzilla.org

  \item BuildBot: http://buildbot.sourceforge.net

  \item CVS: http://www.nongnu.org/cvs

  \item CheckStyle: http://checkstyle.sourceforge.net

  \item CruiseControl: http://cruisecontrol.sourceforge.net

  \item Debian Linux: http://www.debian.org

  \item DocBook: http://www.docbook.org

  \item Doctor Dobb's Journal: http:/www.ddj.com

  \item DrProject: http://www.drproject.org

  \item Eclipse: http://www.eclipse.org

  \item Emacs: http://www.gnu.org/software/emacs

  \item FindBugs: http://findbugs.sourceforge.net

  \item GDB: http://sourceware.org/gdb

  \item Google Code: http://code.google.com

  \item HttpUnit: http://httpunit.sourceforge.net

  \item IRC: http://www.irc.org

  \item JEdit: http://www.jedit.org

  \item JUnitScenario: http://junitscenario.sourceforge.net

  \item JUnit: http://www.junit.org

  \item Javadoc: http://java.sun.com/j2se/javadoc/

  \item LaTeX: http://www.latex-project.org

  \item log4j: http://logging.apache.org/log4j/docs/index.html

  \item LyX: http://www.lyx.org

  \item Make: http://www.gnu.org/software/make/

  \item MathML: http://www.w3.org/Math/

  \item Microsoft Visual Studio: http://msdn.microsoft.com/vstudio

  \item Microsoft Word: http://office.microsoft.com/word

  \item NAnt: http://nant.sourceforge.net

  \item OpenID: http://www.openid.net

  \item OpenOffice: http://www.openoffice.org

  \item Oracle: http://www.oracle.com/

  \item PMD: http://pmd.sourceforge.net

  \item Perforce: http://www.perforce.com

  \item PostgreSQL: http://www.postgresql.org

  \item Python: http://www.python.org

  \item Rake: http://rake.rubyforge.org

  \item Ruby: http://www.ruby-lang.org

  \item SCons: http://www.scons.org

  \item SQLite: http://www.sqlite.org

  \item Selenium: http://www.openqa.org/selenium

  \item SourceForge: http://www.sourceforge.net

  \item SqlUnit: http://sqlunit.sourceforge.net

  \item Subversion: http://subversion.tigris.org

  \item Tomcat: http://tomcat.apache.org

  \item Trac: http://trac.edgewall.org

  \item University of Toronto: http://www.cs.toronto.edu

  \item Valgrind: http://valgrind.org

\end{itemize}

%======================================================================
\chaplbl{Navigating Code}{s:navigate}
%======================================================================

One of the biggest stumbling blocks students face when their project
\emph{doesn't} start from scratch is not knowing how to find their way
around large piles of source code.  \cite{b:spinellis-reading} is a
great place to start learning how to do this; the example below should
give you some pointers as well.

One of the items on my to-do list a couple of years ago was to replace
the default \url{Trac} graphics on the \url{DrProject} web site with
ones that include some reference to the \url{University of Toronto}
and our hippo mascot.  The first step was to figure out exactly what I
was looking for.  If you take a look at the \url{DrProject} site as it
was then, you'd see two logos: a large banner at the top of the page,
and a smaller "Trac Powered" logo at the bottom.  "View Source" showed
that the top one is produced by the following HTML:

\begin{alltt}
<div id="header">
  <a id="logo" xhref="http://trac.edgewall.com/"
     mce_href="http://trac.edgewall.com/">
    <img xsrc="/trac-static/trac_banner.png"
         mce_src="/trac-static/trac_banner.png"
         width="236" height="73" alt="Trac"/>
  </a>
  <hr/>
</div>
\end{alltt}

Step 2: That \code{<div id="header">} tag looked like a good landmark,
so I searched for it in the source code like this:

\begin{alltt}
$ cd ~/drproject/trunk/trac
$ grep 'id="header"' templates/*.cs templates/header.cs:
\end{alltt}

I was relying here on something I already knew about \url{Trac}: the
\url{Python} code generated pages based on \url{ClearSilver}
templates, which lived in the \code{templates} directory, and had a
\code{.cs} extension.  If I didn't know that, I would have run this
command instead:

\begin{alltt}
$ cd ~/drproject/trunk/trac
$ grep 'id="header"' `find . -type f -print | grep -v -e '\.svn'`
\end{alltt}

\noindent (I would pipe the results of \code{find} through a second
\code{grep} to filter out everything in the \code{.svn} directories
that \url{Subversion} uses to manage metadata.)

Step 3 was to take a closer look at the contents of \code{header.cs}:

\begin{alltt}
<div id="header">
  <a id="logo" xhref="<?cs var:header_logo.link ?>">
    <img xsrc="<?cs var:header_logo.src ?>" width="<?cs var:header_logo.width ?>"
     height="<?cs var:header_logo.height ?>" alt="<?cs var:header_logo.alt ?>"/>
  </a>
  <hr/>
</div>
\end{alltt}

The notation \code{var:header\_logo.link} tells \url{ClearSilver} to
look in the data that the \url{Python} CGI builds up for it, find the
\code{header\_logo} key, and insert the value associated with its
\code{link} subkey.  Knowing that, I did another search:

\begin{alltt}
\$ grep header_logo `find . -name '*.py' -print`
./trac/db_default.py:  ('header_logo', 'link', 'http://trac.edgewall.com/'),
./trac/db_default.py:  ('header_logo', 'src', 'trac_banner.png'),
./trac/db_default.py:  ('header_logo', 'alt', 'Trac'),
./trac/db_default.py:  ('header_logo', 'width', '236'),
./trac/db_default.py:  ('header_logo', 'height', '73'),
./trac/web/chrome.py:      logo_src = self.config.get('header_logo', 'src')
./trac/web/chrome.py:      req.hdf['header_logo'] = \{
./trac/web/chrome.py:        'link': self.config.get('header_logo', 'link'),
./trac/web/chrome.py:        'alt': escape(self.config.get('header_logo', 'alt')),
./trac/web/chrome.py:        'width': self.config.get('header_logo', 'width'),
./trac/web/chrome.py:        'height': self.config.get('header_logo', 'height')
\end{alltt}

The first set of hits, from \code{db\_default.py}, were from the code
that builds up a tuple of tuples called \code{default\_config}:

\begin{alltt}
default_config = (('trac', 'htdocs_location', '/trac/'),
                  ...
                  ('header_logo', 'link', 'http://trac.edgewall.com/'),
                  ('header_logo', 'src', 'trac_banner.png'),
                  ('header_logo', 'alt', 'Trac'),
                  ('header_logo', 'width', '236'),
                  ('header_logo', 'height', '73'),
                  ...
                 )
\end{alltt}

I made a note of that, then looked in \code{chrome.py} at the second
set of hits, which all came from the following block of code:

\begin{alltt}
logo_src = self.config.get('header_logo', 'src')
logo_src_abs = logo_src.startswith('http://') or logo_src.startswith('https://')
if not logo_src[0] == '/' and not logo_src_abs:
    logo_src = htdocs_location + logo_src
    req.hdf['header_logo'] = { 'link': self.config.get('header_logo', 'link'),
                               'alt': escape(self.config.get('header_logo', 'alt')),
                               'src': logo_src,
                               'src_abs': logo_src_abs,
                               'width': self.config.get('header_logo', 'width'),
                               'height': self.config.get('header_logo', 'height')
                             }
\end{alltt}

All right: \code{chrome.py} was looking in the configuration object
that \url{Trac} creates each time it services a request, pulling out
the values that describe the header logo, and storing them for
\url{ClearSilver} to use.  That left two questions: how do values get
from \code{db\_default.default\_config} into the configuration object,
and where do files like \code{trac\_banner.png} actually live on disk?

Step 4 was therefore to look for \code{default\_config} in
\code{env.py}.  There were two hits:

\begin{alltt}
def insert_default_data(self):
    ...
    for section,name,value in db_default.default_config:
        self.config.set(section, name, value)
    self.config.save()
\end{alltt}

\noindent and:

\begin{alltt}
def load_config(self):
    self.config = Configuration(os.path.join(self.path, 'conf', 'trac.ini'))
    for section,name,value in db_default.default_config:
        self.config.setdefault(section, name, value)
\end{alltt}

Ah ha!  The configuration object initialized itself by reading from
\code{trac.ini}.  All I had to do now was find \emph{that}{\ldots}

Step 5: We were running \url{Trac} under \url{Apache} on \url{Debian}
Linux, which keeps configuration information under the
\code{/etc/apache2/conf.d} directory.  Sure enough, there was a
\code{trac} file in \code{conf.d} that contained the following lines:

\begin{alltt}
Alias /trac-static/ "/usr/share/trac/htdocs/"
<Directory "/usr/share/trac/htdocs/">
    Options Indexes MultiViews AllowOverride None
    Order allow,deny
    Allow from all
</Directory>
<Directory "/usr/share/trac/cgi-bin">
    AllowOverride None Options ExecCGI -MultiViews +SymLinksIfOwnerMatch
    AddHandler cgi-script .cgi
    Order allow,deny
    Allow from all
</Directory>
<LocationMatch "/trac/[[:alnum:]]+/login">
    AuthPAM_Enabled on AuthName "Pyre Trac"
    AuthType Basic
    require valid-user
</LocationMatch>
\end{alltt}

Remember looking at the HTML source in Step 1?  The image path
specified there was \code{/trac-static/trac\_banner.png}, which
pointed me at the first stanza.  This specified that
\code{/trac-static} was translated into \code{/usr/share/trac/htdocs},
and sure enough, that directory contained the PNG images for the two
logos.  It also contained a \code{trac.ico} file, which produced the
little pawprint logo next to \url{Trac} URLs in the browser and in
Favorites links.

And that was that---the artwork still needed to be done, but at least
I knew where to put files for testing.

Now, you'll probably never need to find \url{Trac} logo files on your
computer, but every time you start work with a new code base there
will be something else you'll need to know.  If there isn't a
comprehensive, up-to-date map of the code (and there never is), the
first step is to find a landmark, like the \code{div} element I picked
in Step 1.  Work backward from that: who touches it?  Where does
\emph{that} code get its inputs?  Keep notes---I had half a page of
them by the time I was done---so that when you hit a roadblock, you
can back up and try another path.  Anything you already know about the
application's architecture will help steer you in the right direction,
so make sure you understand its processing cycle.  And above all,
don't panic, and don't be afraid to ask for help.

%======================================================================
\chaplbl{License}{s:license}
%======================================================================

This work is licensed under the Creative Commons
Attribution-ShareAlike License. To view a copy of this license, visit
http://creativecommons.org/licenses/by-sa/1.0/ or send a letter to
Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305,
USA.  A summary of the license is given below, followed by the full
legal text.  If you wish to distribute some or all of this work under
different terms, please contact the author, Greg Wilson, at
\code{gvwilson@cs.toronto.edu}.

You are free:

\begin{itemize}

  \item to copy, distribute, display, and perform the work

  \item to make derivative works

  \item to make commercial use of the work

\end{itemize}

under the following conditions:

\begin{itemize}

  \item \textbf{Attribution}: You must give the original author credit.

  \item \textbf{Share Alike}: If you alter, transform, or build upon
  this work, you may distribute the resulting work only under a
  license identical to this one.

\end{itemize}

For any reuse or distribution, you must make clear to others the
license terms of this work.

Any of these conditions can be waived if you get permission from the
author.

Your fair use and other rights are in no way affected by the above.

The above is a summary of the full license below.

\begin{alltt}
Creative Commons Legal Code

Attribution-ShareAlike 1.0

CREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE
LEGAL SERVICES. DISTRIBUTION OF THIS DRAFT LICENSE DOES NOT CREATE AN
ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS
INFORMATION ON AN "AS-IS" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES
REGARDING THE INFORMATION PROVIDED, AND DISCLAIMS LIABILITY FOR
DAMAGES RESULTING FROM ITS USE.

License

THE WORK (AS DEFINED BELOW) IS PROVIDED UNDER THE TERMS OF THIS
CREATIVE COMMONS PUBLIC LICENSE ("CCPL" OR "LICENSE"). THE WORK IS
PROTECTED BY COPYRIGHT AND/OR OTHER APPLICABLE LAW. ANY USE OF THE
WORK OTHER THAN AS AUTHORIZED UNDER THIS LICENSE IS PROHIBITED.

BY EXERCISING ANY RIGHTS TO THE WORK PROVIDED HERE, YOU ACCEPT AND
AGREE TO BE BOUND BY THE TERMS OF THIS LICENSE. THE LICENSOR GRANTS
YOU THE RIGHTS CONTAINED HERE IN CONSIDERATION OF YOUR ACCEPTANCE OF
SUCH TERMS AND CONDITIONS.

1. Definitions

a. "Collective Work" means a work, such as a periodical issue,
   anthology or encyclopedia, in which the Work in its entirety in
   unmodified form, along with a number of other contributions,
   constituting separate and independent works in themselves, are
   assembled into a collective whole. A work that constitutes a
   Collective Work will not be considered a Derivative Work (as
   defined below) for the purposes of this License.

b. "Derivative Work" means a work based upon the Work or upon the Work
   and other pre-existing works, such as a translation, musical
   arrangement, dramatization, fictionalization, motion picture
   version, sound recording, art reproduction, abridgment,
   condensation, or any other form in which the Work may be recast,
   transformed, or adapted, except that a work that constitutes a
   Collective Work will not be considered a Derivative Work for the
   purpose of this License.

c. "Licensor" means the individual or entity that offers the Work
   under the terms of this License.

d. "Original Author" means the individual or entity who created the
   Work.

e. "Work" means the copyrightable work of authorship offered under the
   terms of this License.

f. "You" means an individual or entity exercising rights under this
   License who has not previously violated the terms of this License
   with respect to the Work, or who has received express permission
   from the Licensor to exercise rights under this License despite a
   previous violation.

2. Fair Use Rights. Nothing in this license is intended to reduce,
limit, or restrict any rights arising from fair use, first sale or
other limitations on the exclusive rights of the copyright owner under
copyright law or other applicable laws.

3. License Grant. Subject to the terms and conditions of this License,
Licensor hereby grants You a worldwide, royalty-free, non-exclusive,
perpetual (for the duration of the applicable copyright) license to
exercise the rights in the Work as stated below:

a. to reproduce the Work, to incorporate the Work into one or more
   Collective Works, and to reproduce the Work as incorporated in the
   Collective Works;

b. to create and reproduce Derivative Works;

c. to distribute copies or phonorecords of, display publicly, perform
   publicly, and perform publicly by means of a digital audio
   transmission the Work including as incorporated in Collective
   Works;

d. to distribute copies or phonorecords of, display publicly, perform
   publicly, and perform publicly by means of a digital audio
   transmission Derivative Works;

The above rights may be exercised in all media and formats whether now
known or hereafter devised. The above rights include the right to make
such modifications as are technically necessary to exercise the rights
in other media and formats. All rights not expressly granted by
Licensor are hereby reserved.

4. Restrictions. The license granted in Section 3 above is expressly
made subject to and limited by the following restrictions:

a. You may distribute, publicly display, publicly perform, or publicly
   digitally perform the Work only under the terms of this License,
   and You must include a copy of, or the Uniform Resource Identifier
   for, this License with every copy or phonorecord of the Work You
   distribute, publicly display, publicly perform, or publicly
   digitally perform. You may not offer or impose any terms on the
   Work that alter or restrict the terms of this License or the
   recipients' exercise of the rights granted hereunder. You may not
   sublicense the Work. You must keep intact all notices that refer to
   this License and to the disclaimer of warranties. You may not
   distribute, publicly display, publicly perform, or publicly
   digitally perform the Work with any technological measures that
   control access or use of the Work in a manner inconsistent with the
   terms of this License Agreement. The above applies to the Work as
   incorporated in a Collective Work, but this does not require the
   Collective Work apart from the Work itself to be made subject to
   the terms of this License. If You create a Collective Work, upon
   notice from any Licensor You must, to the extent practicable,
   remove from the Collective Work any reference to such Licensor or
   the Original Author, as requested. If You create a Derivative Work,
   upon notice from any Licensor You must, to the extent practicable,
   remove from the Derivative Work any reference to such Licensor or
   the Original Author, as requested.

b. You may distribute, publicly display, publicly perform, or publicly
   digitally perform a Derivative Work only under the terms of this
   License, and You must include a copy of, or the Uniform Resource
   Identifier for, this License with every copy or phonorecord of each
   Derivative Work You distribute, publicly display, publicly perform,
   or publicly digitally perform. You may not offer or impose any
   terms on the Derivative Works that alter or restrict the terms of
   this License or the recipients' exercise of the rights granted
   hereunder, and You must keep intact all notices that refer to this
   License and to the disclaimer of warranties. You may not
   distribute, publicly display, publicly perform, or publicly
   digitally perform the Derivative Work with any technological
   measures that control access or use of the Work in a manner
   inconsistent with the terms of this License Agreement. The above
   applies to the Derivative Work as incorporated in a Collective
   Work, but this does not require the Collective Work apart from the
   Derivative Work itself to be made subject to the terms of this
   License.

c. If you distribute, publicly display, publicly perform, or publicly
   digitally perform the Work or any Derivative Works or Collective
   Works, You must keep intact all copyright notices for the Work and
   give the Original Author credit reasonable to the medium or means
   You are utilizing by conveying the name (or pseudonym if
   applicable) of the Original Author if supplied; the title of the
   Work if supplied; in the case of a Derivative Work, a credit
   identifying the use of the Work in the Derivative Work (e.g.,
   "French translation of the Work by Original Author," or "Screenplay
   based on original Work by Original Author"). Such credit may be
   implemented in any reasonable manner; provided, however, that in
   the case of a Derivative Work or Collective Work, at a minimum such
   credit will appear where any other comparable authorship credit
   appears and in a manner at least as prominent as such other
   comparable authorship credit.

5. Representations, Warranties and Disclaimer

a. By offering the Work for public release under this License,
   Licensor represents and warrants that, to the best of Licensor's
   knowledge after reasonable inquiry:

   i. Licensor has secured all rights in the Work necessary to grant
   the license rights hereunder and to permit the lawful exercise of
   the rights granted hereunder without You having any obligation to
   pay any royalties, compulsory license fees, residuals or any other
   payments;

   ii. The Work does not infringe the copyright, trademark, publicity
   rights, common law rights or any other right of any third party or
   constitute defamation, invasion of privacy or other tortious injury
   to any third party.

b. EXCEPT AS EXPRESSLY STATED IN THIS LICENSE OR OTHERWISE AGREED IN
   WRITING OR REQUIRED BY APPLICABLE LAW, THE WORK IS LICENSED ON AN
   "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR
   IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES REGARDING THE
   CONTENTS OR ACCURACY OF THE WORK.

6. Limitation on Liability. EXCEPT TO THE EXTENT REQUIRED BY
APPLICABLE LAW, AND EXCEPT FOR DAMAGES ARISING FROM LIABILITY TO A
THIRD PARTY RESULTING FROM BREACH OF THE WARRANTIES IN SECTION 5, IN
NO EVENT WILL LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY FOR ANY
SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES
ARISING OUT OF THIS LICENSE OR THE USE OF THE WORK, EVEN IF LICENSOR
HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.

7. Termination

a. This License and the rights granted hereunder will terminate
   automatically upon any breach by You of the terms of this
   License. Individuals or entities who have received Derivative Works
   or Collective Works from You under this License, however, will not
   have their licenses terminated provided such individuals or
   entities remain in full compliance with those licenses. Sections 1,
   2, 5, 6, 7, and 8 will survive any termination of this License.

b. Subject to the above terms and conditions, the license granted here
   is perpetual (for the duration of the applicable copyright in the
   Work). Notwithstanding the above, Licensor reserves the right to
   release the Work under different license terms or to stop
   distributing the Work at any time; provided, however that any such
   election will not serve to withdraw this License (or any other
   license that has been, or is required to be, granted under the
   terms of this License), and this License will continue in full
   force and effect unless terminated as stated above.

8. Miscellaneous

a. Each time You distribute or publicly digitally perform the Work or
   a Collective Work, the Licensor offers to the recipient a license
   to the Work on the same terms and conditions as the license granted
   to You under this License.

b. Each time You distribute or publicly digitally perform a Derivative
   Work, Licensor offers to the recipient a license to the original
   Work on the same terms and conditions as the license granted to You
   under this License.

c. If any provision of this License is invalid or unenforceable under
   applicable law, it shall not affect the validity or enforceability
   of the remainder of the terms of this License, and without further
   action by the parties to this agreement, such provision shall be
   reformed to the minimum extent necessary to make such provision
   valid and enforceable.

d. No term or provision of this License shall be deemed waived and no
   breach consented to unless such waiver or consent shall be in
   writing and signed by the party to be charged with such waiver or
   consent.

e. This License constitutes the entire agreement between the parties
   with respect to the Work licensed here. There are no
   understandings, agreements or representations with respect to the
   Work not specified here. Licensor shall not be bound by any
   additional provisions that may appear in any communication from
   You. This License may not be modified without the mutual written
   agreement of the Licensor and You.

Creative Commons is not a party to this License, and makes no warranty
whatsoever in connection with the Work. Creative Commons will not be
liable to You or any party on any legal theory for any damages
whatsoever, including without limitation any general, special,
incidental or consequential damages arising in connection to this
license. Notwithstanding the foregoing two (2) sentences, if Creative
Commons has expressly identified itself as the Licensor hereunder, it
shall have all rights and obligations of Licensor.

Except for the limited purpose of indicating to the public that the
Work is licensed under the CCPL, neither party will use the trademark
"Creative Commons" or any related trademark or logo of Creative
Commons without the prior written consent of Creative Commons. Any
permitted use will be in compliance with Creative Commons'
then-current trademark usage guidelines, as may be published on its
website or otherwise made available upon request from time to time.

Creative Commons may be contacted at http://creativecommons.org/.
\end{alltt}

\end{document}
